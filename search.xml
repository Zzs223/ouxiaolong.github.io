<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[《WEB开发-HEXO博客搭建》第6章 Hexo 中支持 Mathjax]]></title>
    <url>%2F2018%2F12%2F20%2FHexo%2F%E7%AC%AC6%E7%AB%A0%20Hexo%20%E4%B8%AD%E6%94%AF%E6%8C%81%20Mathjax%2F</url>
    <content type="text"><![CDATA[在 hexo 中，你会发现我们不能用 Latex 语法来书写数学公式，这对于书写学术博客来说是很大的不便，因为我们会经常碰到很多的数学公式推导，但是我们可以通过安装第三方库来解决这一问题。 第一步： 使用Kramed代替 Marked hexo 默认的渲染引擎是 marked，但是 marked 不支持 mathjax。 kramed 是在 marked 的基础上进行修改。我们在工程目录下执行以下命令来安装 kramed.npm uninstall hexo-renderer-marked —savenpm install hexo-renderer-kramed —save 然后，更改/node_modules/hexo-renderer-kramed/lib/renderer.js，更改：12345// Change inline math rulefunction formatText(text) &#123; // Fit kramed's rule: $$ + \1 + $$ return text.replace(/`\$(.*?)\$`/g, '$$$$$1$$$$');&#125; 为：1234// Change inline math rulefunction formatText(text) &#123; return text;&#125; 第二步: 停止使用 hexo-math首先，如果你已经安装 hexo-math, 请卸载它：npm uninstall hexo-math —save 然后安装 hexo-renderer-mathjax 包：npm install hexo-renderer-mathjax —save 第三步: 更新 Mathjax 的 CDN 链接首先，打开/node_modules/hexo-renderer-mathjax/mathjax.html然后，把更改为：1&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"&gt;&lt;/script&gt; 第四步: 更改默认转义规则因为 hexo 默认的转义规则会将一些字符进行转义，比如 _ 转为 , 所以我们需要对默认的规则进行修改.首先， 打开node_modules\kramed\lib\rules\inline.js1escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/, 更改为:1escape: /^\\([`*\[\]()# +\-.!_&gt;])/, 把1em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 更改为:1em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 第五步: 开启mathjax在主题 _config.yml 中开启 Mathjax， 找到 mathjax 字段添加如下代码：12mathjax: enable: true 这一步可选，在博客中开启 Mathjax，， 添加以下内容：123456---title: Testing Mathjax with Hexocategory: Uncategorizeddate: 2017/05/03mathjax: true--- 通过以上步骤，我们就可以在 hexo 中使用 Mathjax 来书写数学公式。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《人工智能-TensorFlow开发笔记》 第2章 TensorFlow环境搭建 - B]]></title>
    <url>%2F2018%2F12%2F18%2FTensorFlow%2F%E7%AC%AC2%E7%AB%A0%20TensorFlow%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%20-%20B%2F</url>
    <content type="text"><![CDATA[2.2 Windows安装TensorFlow在学习TensorFlow或者其他框架，我们关注的是框架本身，当然对于初学者，使用Windows也是一个不错的选择，有很多朋友不熟悉Linux操作系统，初学TensorFlow还是使用Windows吧，废话就不说了，我们开始安装环境吧。配置环境和软件版本：系统环境：Windows10 或者Windows7TensorFlow版本：1.8Python版本：3.6CUDA版本：9.1cuDNN版本： v7.0.5Anaconda版本：3-5.1.0 2.2.1 Anaconda搭建Python环境Anaconda（https://www.anaconda.com/download/#windows）是一个集成了Python的工具包，还包含了Python的一些常用库，如numpy等，所有版本下载地址（https://repo.continuum.io/archive/），外网下载速度很慢，可以到清华大学镜像下载，需要注意的是，配置TensorFlow需要Anaconda3-5.1.0，该版本的Anaconda安装的才是Python3.6，而到目前为止TensorFlow在Windows下只能用Python3.6版本。 ) 图1 就和安装普通的软件一样，全部选择默认即可，注意勾选将python3.6添加进环境变量。安装完成后在开始菜单会出现一个Anaconda3的文件夹。 图2 这样Anaconda就安装好了，我们可以通过下面的命令来查看Anaconda已经安装了哪些包。 运行 开始菜单-&gt;Anaconda3—&gt;Anaconda Prompt ： conda list 可以看到已经安装了numpy、sympy等常用的包。 2.2.2 CPU版TensorFlowTensorFlow有两个版本大家肯定都知道，但是按照官网的建议，安装GPU版之前最好装一遍CPU版的，在这里直接在cmd中利用Anaconda来安装，注意cmd一定要用管理员权限打开。（1）在Anaconda Prompt中利用Anaconda创建一个环境名称为tensorflow ，输入下面命令，用来新建一个conda环境。conda create -n tensorflow 在安装路径下可以看到有TensorFlow目录。 图3 运行开始菜单-&gt;Anaconda3—&gt;Anaconda Navigator，点击左侧的Environments，可以看到tensorflow的环境已经创建好了。 图4 （2）在Anaconda Prompt中启动tensorflow环境： activate tensorflow 激活之后，cmd命令行的前面会有一个写着tensorflow的括号。 注：当不使用tensorflow时，关闭tensorflow环境，命令为：deactivate （3）安装cpu版本的TensorFlow在安装之前先更新一下环境： python –m pip install —upgrade pip 执行一下命令进行安装TensorFlow。 pip install —upgrade —ignore-installed tensorflow 这样tensorflow cpu版本就安装好了。（4）测试tensorflow在Anaconda Prompt中启动tensorflow环境，并进入python环境。使用管理员权限打开cmd，键入activate tensorflow，继续键入python，以执行python语句，依次键入下列代码：1234import tensorflow as tfhello = tf.constant('Hello, TensorFlow!')sess = tf.Session()print(sess.run(hello)) 返回helloword表示安装成功。【注】我们在Anaconda自带的ipython 和Spyder中import tensorflow的时候一直失败，提示 No module named ‘tensorflow’，如下图，那是因为我们没有在tensorflow的环境下打开它们。 为了能在ipython 和Spyder中使用tensorflow，我们需要在tensorflow的环境中安装这两个的插件。打开Anaconda Navigator，选择Not installed，找到 ipython和Spyder并安装，笔者这里已经安装好，所以在这个页面没有显示。 图5 切换到installed，可以看到两个都已经安装好，其实可以按照自己的需要安装。下图显示已经安装好的Spyder。当然，在此之前安装好TensorFlow，不然也是不能运行的。 图6 图7 安装好插件后，我们需要测试一下。在Anaconda Prompt中启动tensorflow环境，并运行ipython，import tensorflow发现成功。 图8 同样，在Anaconda Prompt中启动tensorflow环境，并运行Spyder，等一会儿后会启动Spyder IDE，import tensorflow 同样成功。 图9 2.2.3 GPU环境搭建1.确定显卡是否支持CUDACUDA是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。CUDA环境搭建需要依赖电脑的GPU，我们需要先查看GPU版本。 【计算机】-&gt;【控制面板】-&gt;【系统和安全】-&gt;【系统】-&gt;【设备管理器】可以查看显卡型号。 图10查看英伟达型号 我电脑的GPU型号为GTX 1050Ti，其计 算能力为6.1GPU的计算能力可以在NVIDIA官网（https://developer.nvidia.com/cuda-gpus）查看。 图11 2.查看CUDA版本支持在安装CUDA前。先查看硬件可支持的版本，单击【右键】-&gt;【NVIDIA控制面板】可以进入NVIDIA控制面板。 图12 单击【帮助】-&gt;【系统信息】，进入系统系统后，单击【组件】，即可查看版本。 图13 图14 【注1】可通过NVIDIA控制面板首页的版本号388.75查看CUDA支持的版本。 表 1 CUDA工具箱和兼容的驱动程序版本 （表来源：https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html）根据配置参数，笔者可以选择CUDA9.2以下的版本，笔者选择安装CUDA9.1。 【注2】选择硬件不能支持的版本也许可以安装，但是有的功能是不能实现的，切记！在NVIDIA官网（https://developer.nvidia.com/cuda-toolkit-archive）下载与系统对应的CUDA9.1安装包并安装。 图15 3.安装CUDA9.1CUDA安装包下载后接下来就是安装了。和普通的安装软件一样，笔者就不一一赘述了。 4.配置cuDNN v7.0.5cuDNN是用于深层神经网络的GPU加速的原始库。 在官网下载（https://developer.nvidia.com/rdp/cudnn-archive）与CUDA版本和操作系统对应的cuDNN，将其解压后放在CUDA9.1的安装路径下。 图16cuDNN下载 ![在这里插入图片描述](第2章 TensorFlow环境搭建 - B/t17.png) 图17 其实解压出来的三个文件夹在CUDA的安装路径中是存在的，这三个文件夹里放的其实是使用cuDNN所需呀的文件。 【注】整个过程是不需要配置环境变量的，因为在安装CUDA的时候环境变量已经配置好了，配置cuDNN也只是把cuDNN需要的文件放到自动定义好的路径里面。]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《人工智能-TensorFlow开发笔记》 第2章 TensorFlow环境搭建 - A]]></title>
    <url>%2F2018%2F12%2F18%2FTensorFlow%2F%E7%AC%AC2%E7%AB%A0%20TensorFlow%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%20-%20A%2F</url>
    <content type="text"><![CDATA[2.1 Linux安装TensorFlow2.1.1基于Pip的安装2.1.1.1Pip安装Pip 是一个 Python 的软件包安装与管理工具，在安装 TensorFlow 过程中要涉及安装或升级的包详见列表 https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py 首先安装 pip (或 Python3 的 pip3 )：  查看系统所安装的python版本$python –V（版本查看）  安装python对应版本的pip和依赖包若python版本为2.7，则输入如下命令： $ sudo apt-get install python-pip python-dev 若python版本为3.x，则输入如下命令：$sudo apt-get install python3-pip python3-dev  升级pip版本在装tensorflow之前，不管是不是最新的pip版本，都要更新一下，具体命令如下： python 2.7版本：$sudo pip install —upgrade pippython 3.x版本：$sudo pip3 install —upgrade pip 2.1.1.2安装 TensorFlow CPU安装 Ubuntu/Linux 64-bit, CPU only, Python 2.7: $ sudo pip install —upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl 或者$sudo pip install tensorflow或者$sudo pip install —upgrade TF_PYTHON_URL Ubuntu/Linux 64-bit, CPU only, Python 3.4: $ sudo pip3 install —upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl或者$sudo pip3 install tensorflow或者$sudo pip3 install —upgrade TF_PYTHON_URL 其中，TF_PYTHON_URL为TensrorFlow的python包，不通的操作系统、python版本、GPU支持状况需要选择不同的包，例如OS为Linux，python版本为3.4，仅支持CPU的情况下，TF_PYTHON_URL应当替换为https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.1.0-cp34-cp34m-linux_x86_64.whl  GPU安装 Ubuntu/Linux 64-bit, GPU enabled, Python 2.7. Requires CUDA toolkit 7.5 and CuDNN v4 For other versions, see “Install from sources” below. $ sudo pip install —upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl 或者$sudo pip install tensorflow-gpu Ubuntu/Linux 64-bit, GPU enabled, Python 3.4. Requires CUDA toolkit 7.5 and CuDNN v. For other versions, see “Install from sources” below. $ sudo pip3 install —upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl或者$sudo pip3 install tensorflow-gpu/ 【注1】笔者环境Ubuntu16.04+Python3+CPU，安装过程如下所示。（安装工程比较慢，需要耐心等待…） 成功安装如下所示。 【注2】如果之前安装过 TensorFlow &lt; 0.7.1 的版本,应该先使用 pip uninstall 卸载 TensorFlow 和 protobuf ,保证获取的是一个最新 protobuf 依赖下的安装包。 【注3】在Ubuntu16.04系统中，默认使用的还Python2.7，,关于Python版本的切换，请参考如下文章：https://blog.csdn.net/u013162035/article/details/80339631 2.1.1.3 TensorFlow验证验证tensorflow是否安装成功，启动终端，新建一个Python脚本。 $vi test.py 然后输入以下代码，并保存。 123456import tensorflow as tfa=tf.constant([1.0,2.0,3.0],shape=[3],name=&apos;a&apos;)b=tf.constant([1.0,2.0,3.0],shape=[3],name=&apos;b&apos;)c=a+bsess=tf.Session(config=tf.ConfigProto(log_device_placement=True))print(sess.run(c)) 执行脚本。 $python test.py 如果输出以下内容则代表安装成功。 2.1.2基于 Docker 的安装我们也支持通过 Docker （https://www.docker.com/）运行 TensorFlow. 该方式的优点是不用操心软件依赖问题。首先, 安装 Docker（https://docs.docker.com/install/#server）。 一旦 Docker 已经启动运行, 可以通过命令启动一个容器: $ docker run -it b.gcr.io/tensorflow/tensorflow 该命令将启动一个已经安装好 TensorFlow 及相关依赖的容器.其它镜像默认的 Docker 镜像只包含启动和运行 TensorFlow 所需依赖库的一个最小集. 我们额外提供了 下面的容器, 该容器同样可以通过上述 docker run 命令安装:b.gcr.io/tensorflow/tensorflow-full: 镜像中的 TensorFlow 是从源代码完整安装的, 包含了编译和运行 TensorFlow 所需的全部工具. 在该镜像上, 可以直接使用源代码进行实验, 而不需要再安装上述的任何依赖。 2.1.3基于 VirtualEnv 的安装我们推荐使用 virtualenv 创建一个隔离的容器, 来安装 TensorFlow. 这是可选的, 但是这样做能使排查安装问题变得更容易。 首先, 安装所有必备工具： $ sudo apt-get install python-pip python-dev python-virtualenv 接下来, 建立一个全新的 virtualenv 环境. 为了将环境建在 ~/tensorflow 目录下, 执行： $ virtualenv —system-site-packages ~/tensorflow$ cd ~/tensorflow 然后, 激活 virtualenv： $ source bin/activate # 如果使用 bash$ source bin/activate.csh # 如果使用 csh(tensorflow)$ # 终端提示符应该发生变化 在 virtualenv 内, 安装 TensorFlow：1(tensorflow) $ pip install --upgrade &lt;$url_to_binary.whl&gt; 接下来, 使用类似命令运行 TensorFlow 程序：12345(tensorflow)$ cd tensorflow/models/image/mnist(tensorflow)$ python convolutional.py# 当使用完 TensorFlow(tensorflow)$ deactivate # 停用 virtualenv$ # 你的命令提示符会恢复原样 2.1.4基于 Anaconda 的安装Anaconda （https://www.anaconda.com/what-is-anaconda/）是一个集成许多第三方科学计算库的 Python 科学计算环境（https://conda.io/docs/user-guide/tasks/manage-environments.html），Anaconda 使用 conda 作为自己的包管理工具,同时具有自己的计算环境,类似 Virtualenv. 和 Virtualenv 一样，不同 Python 工程需要的依赖包，conda 将他们存储在不同的地方。 TensorFlow 上安装的 Anaconda 不会对之前安装的 Python 包进行覆盖。1.安装 Anaconda :参考 Anaconda 的下载页面的指导（https://www.anaconda.com/download/） 2.建立一个 conda 计算环境建立一个 conda 计算环境名字叫tensorflow： Python 2.7$ conda create -n tensorflow python=2.7&lt;/pre&gt; Python 3.4$ conda create -n tensorflow python=3.4&lt;/pre&gt; 3.激活环境,使用 conda 安装 TensorFlow激活tensorflow环境,然后使用其中的 pip 安装 TensorFlow. 当使用easy_install使用—ignore-installed标记防止错误的产生。1234567$ source activate tensorflow(tensorflow)$ # Your prompt should change# Ubuntu/Linux 64-bit, CPU only, Python 2.7:(tensorflow)$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl# Ubuntu/Linux 64-bit, GPU enabled, Python 2.7. Requires CUDA toolkit 7.5 and CuDNN v4.# For other versions, see &quot;Install from sources&quot; below.(tensorflow)$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl 对于 Python 3.x :1234567$ source activate tensorflow(tensorflow)$ # Your prompt should change# Ubuntu/Linux 64-bit, CPU only, Python 3.4:(tensorflow)$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0rc0-cp34-cp34m-linux_x86_64.whl# Ubuntu/Linux 64-bit, GPU enabled, Python 3.4. Requires CUDA toolkit 7.5 and CuDNN v4.# For other versions, see &quot;Install from sources&quot; below.(tensorflow)$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp34-cp34m-linux_x86_64.whl conda 环境激活后,你可以测试。当你不用 TensorFlow 的时候,关闭环境:12 (tensorflow)$ source deactivate$ # Your prompt should change back 再次使用的时候再激活 :123456$ source activate tensorflow(tensorflow)$ # Your prompt should change.# Run Python programs that use TensorFlow....# When you are done using TensorFlow, deactivate the environment.(tensorflow)$ source deactivate 4.测试 (可选) 启用 GPU 支持如果你使用 pip 二进制包安装了开启 GPU 支持的 TensorFlow, 你必须确保 系统里安装了正确的 CUDA sdk 和 CUDNN 版本. 请参间 CUDA 安装教程。 你还需要设置 LD_LIBRARY_PATH 和 CUDA_HOME 环境变量. 可以考虑将下面的命令 添加到 ~/.bash_profile 文件中, 这样每次登陆后自动生效. 注意, 下面的命令 假定 CUDA 安装目录为 /usr/local/cuda:export LD_LIBRARY_PATH=”$LD_LIBRARY_PATH:/usr/local/cuda/lib64”export CUDA_HOME=/usr/local/cuda  运行 TensorFlow打开一个 python 终端：1234567891011$ python&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')&gt;&gt;&gt; sess = tf.Session()&gt;&gt;&gt; print sess.run(hello)Hello, TensorFlow!&gt;&gt;&gt; a = tf.constant(10)&gt;&gt;&gt; b = tf.constant(32)&gt;&gt;&gt; print sess.run(a+b)42&gt;&gt;&gt; 2.1.5源码安装1.克隆 TensorFlow 仓库 $ git clone --recurse-submodules https://github.com/tensorflow/tensorflow 【注】--recurse-submodules 参数是必须得, 用于获取 TesorFlow 依赖的 protobuf 库. **2.安装 Bazel** 首先依照教程（https://docs.bazel.build/versions/master/install.html）安装 Bazel 的依赖. 然后在 链接（https://github.com/bazelbuild/bazel/releases）中下载适合你的操作系统的最新稳定版, 最后按照下面脚本执行： $ chmod +x PATH_TO_INSTALL.SH $ ./PATH_TO_INSTALL.SH --user 注意把 PATH_TO_INSTALL.SH 替换为你下载的安装包的文件路径. 将执行路径 output/bazel 添加到 $PATH 环境变量中. **3.安装其他依赖** - # For Python 2.7: $ sudo apt-get install python-numpy swig python-dev python-wheel - # For Python 3.x $ sudo apt-get install python3-numpy swig python3-dev python3-wheel 4.安装 CUDA (在 Linux 上开启 GPU 支持)（可选）为了编译并运行能够使用 GPU 的 TensorFlow, 需要先安装 NVIDIA 提供的 Cuda Toolkit 7.0 和 CUDNN 6.5 V2.TensorFlow 的 GPU 特性只支持 NVidia Compute Capability &gt;= 3.5 的显卡. 被支持的显卡 包括但不限于：NVidia TitanNVidia Titan XNVidia K20NVidia K40  下载并安装 Cuda Toolkit 7.0下载地址（https://developer.nvidia.com/cuda-toolkit-70）将工具安装到诸如 /usr/local/cuda 之类的路径.  下载并安装 CUDNN Toolkit 6.5下载地址（https://developer.nvidia.com/rdp/cudnn-archive）解压并拷贝 CUDNN 文件到 Cuda Toolkit 7.0 安装路径下. 假设 Cuda Toolkit 7.0 安装 在 /usr/local/cuda, 执行以下命令:tar xvzf cudnn-6.5-linux-x64-v2.tgzsudo cp cudnn-6.5-linux-x64-v2/cudnn.h /usr/local/cuda/includesudo cp cudnn-6.5-linux-x64-v2/libcudnn* /usr/local/cuda/lib64  配置 TensorFlow 的 Cuda 选项从源码树的根路径执行: $ ./configure Do you wish to bulid TensorFlow with GPU support? [y/n] yGPU support will be enabled for TensorFlowPlease specify the location where CUDA 7.0 toolkit is installed. Refer toREADME.md for more details. [default is: /usr/local/cuda]: /usr/local/cudaPlease specify the location where CUDNN 6.5 V2 library is installed. Refer toREADME.md for more details. [default is: /usr/local/cuda]: /usr/local/cudaSetting up Cuda includeSetting up Cuda lib64Setting up Cuda binSetting up Cuda nvvmConfiguration finished这些配置将建立到系统 Cuda 库的符号链接. 每当 Cuda 库的路径发生变更时, 必须重新执行上述 步骤, 否则无法调用 bazel 编译命令.  编译目标程序, 开启 GPU 支持从源码树的根路径执行：$ bazel build -c opt —config=cuda //tensorflow/cc:tutorials_example_trainer$ bazel-bin/tensorflow/cc/tutorials_example_trainer —use_gpu # 大量的输出信息. 这个例子用 GPU 迭代计算一个 2x2 矩阵的主特征值 (major eigenvalue).# 最后几行输出和下面的信息类似.000009/000005 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]000006/000001 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427] 注意, GPU 支持需通过编译选项 “—config=cuda” 开启. 已知问题尽管可以在同一个源码树下编译开启 Cuda 支持和禁用 Cuda 支持的版本, 我们还是推荐在 在切换这两种不同的编译配置时, 使用 “bazel clean” 清理环境. 在执行 bazel 编译前必须先运行 configure, 否则编译会失败并提示错误信息. 未来, 我们可能考虑将 configure 步骤包含在编译过程中, 以简化整个过程, 前提是 bazel 能够提供新的特性支持这样。 【注】常见问题 1.GPU 相关问题如果在尝试运行一个 TensorFlow 程序时出现以下错误:ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory请确认你正确安装了 GPU 支持, 参见 相关章节. 2. Linux安装问题如果出现错误:1234... &quot;__add__&quot;, &quot;__radd__&quot;, ^SyntaxError: invalid syntax 解决方案: 确认正在使用的 Python 版本为 Python 2.7. 参考地址：英文原文中文翻译官网参考文档地址]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《人工智能-TensorFlow开发笔记》第6章 损失函数与代价函数]]></title>
    <url>%2F2018%2F12%2F15%2FTensorFlow%2F%E7%AC%AC6%E7%AB%A0%20%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[首先需要明确损失函数与代价函数的区别与联系。在 Coursera：Neural Networks and Deep Learning 课程中，Andrew Ng 给出的解释如下： The loss function computes the error for a single training example; the cost function is the average of the loss funcitons of the entire training set. 损失函数(Loss function)是定义在单个训练样本的损失/误差，也就是就算一个样本的误差，比如我们想要分类，就是预测的类别和实际类别的区别，是一个样本的哦，用L表示。 代价函数(Cost function)是定义在整个训练集整体的误差描述，也就是所有样本的误差的总和的平均，也就是损失函数的总和的平均，有没有这个平均其实不会影响最后的参数的求解结果。 所以说两个不是一个东西，很多人把它们混为一谈这是不对的。好了，开始今天的正题吧。 6.1常见的损失函数损失函数（loss function）是用来估量你模型的预测值 f(x)与真实值 Y的不一致程度，它是一个非负实值函数,通常使用 来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下式子： \theta^* = \arg \min_\theta \frac{1}{N}{}\sum_{i=1}^{N} L(y_i, f(x_i; \theta)) + \lambda\ \Phi(\theta)其中，前面的均值函数表示的是经验风险函数，$L$代表的是损失函数，后面的Φ是正则化项（regularizer）或者叫惩罚项（penalty term），它可以是$L1$，也可以是$L2$，或者其他的正则函数。整个式子表示的意思是找到使目标函数最小时的θ值。下面主要列出几种常见的损失函数。【注】Object Function（目标函数 ）定义为：Cost Function + 正则化项。目标函数(Objective function)就是有某个（最优化）目标的函数。 图1常见的损失函数 6.1.1 0-1损失函数和绝对值损失函数可以看从图1看出，该损失函数的意义就是，当预测错误时，损失函数值为1，预测正确时，损失函数值为0。该损失函数不考虑预测值和真实值的误差程度，也就是只要预测错误，预测错误差一点和差很多是一样的。 感知机就是用的这种损失函数。但是由于相等这个条件太过严格，因此我们可以放宽条件，即满足$|Y-f(X)|&lt;T$ 时认为相等。  绝对值损失函数 L(Y,f(X))=|Y-f(X)|6.1.2平方损失函数（Square Loss）（最小二乘法, Ordinary Least Squares ）最小二乘法是线性回归的一种，OLS将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布（为什么假设成高斯分布呢？其实这里隐藏了一个小知识点，就是中心极限定理，可以参考【central limit theorem】 最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小。换言之，OLS是基于距离的，而这个距离就是我们用的最多的欧几里得距离。为什么它会选择使用欧式距离作为误差度量呢（即Mean squared error， MSE），主要有以下几个原因：  简单，计算方便； 欧氏距离是一种很好的相似性度量标准； 在不同的表示域变换后特征性质不变。 平方损失（Square loss）的标准形式如下： L(Y-f(X))=(Y-f(X))^26.1.3 log对数损失函数（Cross Entropy Loss）（逻辑回归与Softmax 分类）平方损失函数可以通过线性回归在假设样本是高斯分布的条件下推导得到，而逻辑回归得到的并不是平方损失。在逻辑回归的推导中，它假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：最小化负的似然函数（即$max F(y, f(x)) —&gt; min -F(y, f(x)))$。从损失函数的视角来看，它就成了log损失函数了。log损失函数的标准形式： L(Y,P(Y|X)) = -\log P(Y|X)刚刚说到，取对数是为了方便计算极大似然估计，因为在MLE中，直接求导比较困难，所以通常都是先取对数再求导找极值点。损失函数$L(Y, P(Y|X))$表达的是样本$X$在分类$Y$的情况下，使概率$P(Y|X)$达到最大值（换言之，就是利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者说什么样的参数才能使我们观测到目前这组数据的概率最大）。因为log函数是单调递增的，所以$logP(Y|X)$也会达到最大值，因此在前面加上负号之后，最大化$P(Y|X)$就等价于最小化$L$了。 逻辑回归的$P(Y=y|x)$表达式如下（为了将类别标签$y$统一为1和0，下面将表达式分开表示）： 将它带入到上式，通过推导可以得到logistic的损失函数表达式，如下： 6.1.4指数损失函数（Exponential Loss）（Adaboost）学过Adaboost算法的人都知道，它是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。在Adaboost中，经过m此迭代之后，可以得到 $f_m(x)$： Adaboost每次迭代时的目的是为了找到最小化下列式子时的参数$α$和$G$： 而指数损失函数(exp-loss）的标准形式如下： 关于Adaboost的推导，可以参考Wikipedia：AdaBoost或者《统计学习方法》P145. 6.1.5铰链损失函数（Hinge Loss）（SVM）在机器学习算法中，hinge损失函数和SVM是息息相关的。在线性支持向量机中，最优化问题可以等价于下列式子： 下面来对式子做个变形，令： 于是，原式就变成了： 如若取 $\lambda=\frac{1}{2C}$，式子就可以表示成： 可以看出，该式子与下式非常相似： 前半部分中的$l$就是hinge损失函数，而后面相当于$L2$正则项。Hinge 损失函数的标准形式： 可以看出，当$|y|&gt;=1$时，$L(y)=0$。 更多内容，参考Hinge-loss。补充一下：在libsvm中一共有4中核函数可以选择，对应的是-t参数分别是： 线性核； 多项式核； RBF核； sigmoid核。 图2 6.2常见的代价函数前文介绍了常见的损失函数，接下来介绍常见的代价函数。这是在前文的基础上推到的。 6.2.1平方代价函数当样本个数为n时，此时的代价函数变为： C(Y,f(X))= {}\sum_{i=1}^{n} (Y-f(X))^2 $$_ $Y-f(X)$表示的是残差，整个式子表示的是残差的平方和，而我们的目的就是最小化这个目标函数值（注：该式子未加入正则项），也就是最小化残差的平方和（residual sum of squares，RSS）。 而在实际应用中，通常会使用均方差（MSE）作为一项衡量指标，公式如下： $$MSE = \frac{1}{n} \sum_{i=1} ^{n} (\tilde{Y_i} - Y_i )^2上面提到了线性回归，这里额外补充一句，我们通常说的线性有两种情况，一种是因变量$y$是自变量$x$的线性函数，一种是因变量$y$是参数$α$的线性函数。在机器学习中，通常指的都是后一种情况。 6.2.2 log对数代价函数逻辑回归最后得到的目标式子如下： J(\theta) = - \frac{1}{m} \sum_{i=1}^m \left [ y^{(i)} \log h_{\theta}(x^{(i)}) + (1-y^{(i)}) \log(1-h_{\theta}(x^{(i)})) \right ]上面是针对二分类而言的。这里需要解释一下：之所以有人认为逻辑回归是平方损失，是因为在使用梯度下降来求最优解的时候，它的迭代式子与平方损失求导后的式子非常相似，从而给人一种直观上的错觉。 6.2.3指数代价函数（Adaboost）Adaboost的目标式子就是指数损失，在给定￥n$个样本的情况下，Adaboost的损失函数为： C(y,f(x)) = \frac{1}{n} \sum_{i=1} ^{n} exp[-y_if(x_i)]6.2.4铰链代价函数（Hinge Loss）铰链损失函数的代价函数如下：]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《人工智能-TensorFlow开发笔记》第5章 Tensorboard]]></title>
    <url>%2F2018%2F12%2F05%2FTensorFlow%2F%E7%AC%AC5%E7%AB%A0%20Tensorboard%2F</url>
    <content type="text"><![CDATA[TensorBoard是一个可视化工具，能够有效地展示Tensorflow在运行过程中的计算图、各种指标随着时间的变化趋势以及训练中使用到的数据信息。 5.1 Tensorboard网络结构Tensorflow 自带 tensorboard ，可以自动显示我们所建造的神经网络流程图，有助于你发现编程中间的问题和疑问。 图1 同时我们也可以展开看每个layer中的一些具体的结构： 图2 好了，通过阅读代码和之前的图片我们大概知道了此处是有一个输入层（inputs），一个隐含层（layer），还有一个输出层（output） 现在可以看看如何进行可视化。 我们先看完完整代码吧。 【代码参看附件test1_tensorboard1.py】12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt#需要安装才可使用#添加层def add_layer(inputs, in_size, out_size, activation_function=None): #线性模型 with tf.name_scope(&apos;layer&apos;): with tf.name_scope(&apos;weights&apos;): Weights = tf.Variable(tf.random_normal([in_size, out_size]), name=&apos;W&apos;) with tf.name_scope(&apos;biases&apos;): biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name=&apos;b&apos;) with tf.name_scope(&apos;Wx_plus_b&apos;): Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases) if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b, ) return outputs#【1】创建原始数据，及要训练的数据x_data = np.linspace(-1,1,300)[:, np.newaxis]noise = np.random.normal(0, 0.05, x_data.shape)y_data = np.square(x_data) - 0.5 + noise#【2】定义节点，输入网络with tf.name_scope(&apos;inputs&apos;): xs = tf.placeholder(tf.float32, [None, 1],name=&apos;x_input&apos;) ys = tf.placeholder(tf.float32, [None, 1],name=&apos;y_input&apos;)#【3】定义神经层：隐藏层和预测层#添加隐藏层，输入值是 xs，在隐藏层有 10 个神经元 l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)#添加输出层，输入值是隐藏层 l1，在预测层输出 1 个结果prediction = add_layer(l1, 10, 1, activation_function=None)#【4】定义损失函数，误差的均方差with tf.name_scope(&apos;loss&apos;): loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1]))#【5】选择 optimizer 使 loss 达到最小，选择梯度下降的方法训练数据with tf.name_scope(&apos;train&apos;): train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)#【6】初始化数据，tf 的必备步骤，主要声明了变量，就必须初始化才能用init = tf.initialize_all_variables()#【7】创建Session会话。启动图sess = tf.Session()#writer = tf.train.SummaryWriter(&quot;logs/&quot;, sess.graph)#新版的TensorFlow已经弃用writer = tf.summary.FileWriter(&quot;logs/&quot;,sess.graph)#加载文件#上面定义的都没有运算，直到 sess.run 才会开始运算sess.run(init) 运行成功后会在你存放文件的文件夹下生成下列文件。 图3生成的网络图文件 打开 terminal，进入你存放的文件夹地址上一层，笔者存放的文件夹是logs。因此，要进入logs的上一级文件，运行命令 tensorboard —logdir=’logs/‘ 后会返回一个地址。 地址为：http://(主机名):6006/。 然后用浏览器打开这个地址。 图4 点击 graph 标签栏下就可以看到流程图了： ![这里写图片描述](第5章 Tensorboard/图5.png) 图5【注1】在Windows平台上运行命令应用tensorboard —logdir=logs/【注2】笔者在上述代码中已经进行详细注释了，再次就不在赘述了。 5.2 Tensorboard网络运行好了，前文讲解的是神经网络的图，接下来在上文的基础上继续使用tensorboard。我们直接上代码吧。【代码参看附件test2_tensorboard2】12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt#需要安装才可使用#添加层def add_layer(inputs, in_size, out_size, n_layer, activation_function=None): # add one more layer and return the output of this layer layer_name = &apos;layer%s&apos; % n_layer #线性模型 with tf.name_scope(&apos;layer&apos;): with tf.name_scope(&apos;weights&apos;): Weights = tf.Variable(tf.random_normal([in_size, out_size]), name=&apos;W&apos;) tf.summary.histogram(layer_name + &apos;/weights&apos;, Weights) #tf.histogram_summary(layer_name + &apos;/weights&apos;, Weights)#新版已经废弃 with tf.name_scope(&apos;biases&apos;): biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name=&apos;b&apos;) with tf.name_scope(&apos;Wx_plus_b&apos;): Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases) tf.summary.histogram(layer_name + &apos;/biases&apos;, biases) if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b, ) tf.summary.histogram(layer_name + &apos;/outputs&apos;, outputs) return outputs#【1】创建原始数据，及要训练的数据x_data = np.linspace(-1,1,300)[:, np.newaxis]noise = np.random.normal(0, 0.05, x_data.shape)y_data = np.square(x_data) - 0.5 + noise#【2】定义节点，输入网络with tf.name_scope(&apos;inputs&apos;): xs = tf.placeholder(tf.float32, [None, 1],name=&apos;x_input&apos;) ys = tf.placeholder(tf.float32, [None, 1],name=&apos;y_input&apos;)#【3】定义神经层：隐藏层和预测层#添加隐藏层，输入值是 xs，在隐藏层有 10 个神经元 l1 = add_layer(xs, 1, 10, n_layer=1, activation_function=tf.nn.relu)#添加输出层，输入值是隐藏层 l1，在预测层输出 1 个结果prediction = add_layer(l1, 10, 1, n_layer=2, activation_function=None)#【4】定义损失函数，误差的均方差with tf.name_scope(&apos;loss&apos;): loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1])) tf.summary.scalar(&apos;loss&apos;, loss)#【5】选择 optimizer 使 loss 达到最小，选择梯度下降的方法训练数据with tf.name_scope(&apos;train&apos;): train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)#【6】初始化数据，tf 的必备步骤，主要声明了变量，就必须初始化才能用init = tf.initialize_all_variables()#【7】创建Session会话。启动图sess = tf.Session()#merged = tf.merge_all_summaries()#新版已经废弃merged = tf.summary.merge_all()#writer = tf.train.SummaryWriter(&quot;logs/&quot;, sess.graph)#新版的TensorFlow已经弃用writer = tf.summary.FileWriter(&quot;logs/&quot;,sess.graph)#加载文件#上面定义的都没有运算，直到 sess.run 才会开始运算sess.run(init)#【8】训练数据for i in range(1000): sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;) if i % 50 == 0: result = sess.run(merged, feed_dict=&#123;xs: x_data, ys: y_data&#125;) writer.add_summary(result, i) 运行成功后，可以通过网页查看。 图6 【注1】前文的几个代码请对比查看其中的异同，笔者在代码中也已经详细的注释了，请仔细阅读吧。【注2】在使用Spyder的时候，如果多次运行代码，TensorBoard会跟踪生成多个结果。因此注意在每次查看TensorBoard前Restart Kernel。 图7 本章参考代码点击进入 TensorFlow中API版本容错 1234567891011#writer = tf.train.SummaryWriter(&quot;logs/&quot;, sess.graph)#新版的TensorFlow已经弃用writer = tf.summary.FileWriter(&quot;logs/&quot;,sess.graph)#加载文件 #tf.histogram_summary(layer_name + &apos;/weights&apos;, Weights)#新版已经废弃tf.summary.histogram(layer_name + &apos;/weights&apos;, Weights) #tf.scalar_summary(&apos;loss&apos;, loss)#新版已经废弃tf.summary.scalar(&apos;loss&apos;, loss) #merged = tf.merge_all_summaries()#新版已经废弃merged = tf.summary.merge_all()]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《人工智能-TensorFlow开发笔记》第4章 搭建神经网络]]></title>
    <url>%2F2018%2F12%2F05%2FTensorFlow%2F%E7%AC%AC4%E7%AB%A0%20%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[4.1神经网络基本概念前文，笔者带领大家建立了一个线性模型，并通过TensorFlow将其实现，前面只是介绍了TensorFlow的基本概念。本文将介绍神经网络的基本概念，神经网络是一种数学模型，是存在于计算机的神经系统，由大量的神经元相连接并进行计算，在外界信息的基础上，改变内部的结构，常用来对输入和输出间复杂的关系进行建模。神经网络由大量的节点和之间的联系构成，负责传递信息和加工信息，神经元也可以通过训练而被强化。 下图就是一个神经网络系统，它由很多层构成。输入层就是负责接收信息，比如说一只猫的图片。输出层就是计算机对这个输入信息的认知，它是不是猫。隐藏层就是对输入信息的加工处理。 图1 神经网络是如何被训练的，首先它需要很多数据。比如他要判断一张图片是不是猫。就要输入上千万张的带有标签的猫猫狗狗的图片，然后再训练上千万次。 神经网络训练的结果有对的也有错的，如果是错误的结果，将被当做非常宝贵的经验，那么是如何从经验中学习的呢？就是对比正确答案和错误答案之间的区别，然后把这个区别反向的传递回去，对每个相应的神经元进行一点点的改变。那么下一次在训练的时候就可以用已经改进一点点的神经元去得到稍微准确一点的结果。 神经网络是如何训练的呢？每个神经元都有属于它的激活函数，用这些函数给计算机一个刺激行为。 图2 在第一次给计算机看猫的图片的时候，只有部分的神经元被激活，被激活的神经元所传递的信息是对输出结果最有价值的信息。如果输出的结果被判定为是狗，也就是说是错误的了，那么就会修改神经元，一些容易被激活的神经元会变得迟钝，另外一些神经元会变得敏感。这样一次次的训练下去，所有神经元的参数都在被改变，它们变得对真正重要的信息更为敏感。 图3 好了，总结一下，不管有多少层网络，宏观上看就三层：输入层，隐藏层和输出层；在输入层输入数据，然后数据飞到隐藏层飞到输出层，用梯度下降处理，梯度下降会对几个参数进行更新和完善，更新后的参数再次跑到隐藏层去学习，这样一直循环直到结果收敛。 图4 TensorFlow的模型结构 动图链接 4.2搭建神经网络的基本流程搭建神经网络基本流程：  训练的数据； 定义节点准备接收数据； 定义神经层：隐藏层和预测层 定义 loss 表达式 选择 optimizer 使 loss 达到最小 本文将在前文的基础上，添加神经层，在具体实现基本流程之前，我们先明确几个基本概念。  激励函数激励函数一般用于神经网络的层与层之间，上一层的输出通过激励函数的转换之后输入到下一层中。神经网络模型是非线性的，如果没有使用激励函数，那么每一层实际上都相当于矩阵相乘。经过非线性的激励函数作用，使得神经网络有了更多的表现力。 那么为何要使用激励函数呢？因为线性函数有一个特点，那就是线性函数的组合还是线性函数，这也就以为这不论你所设计的神经网络有多深，多么复杂，只要里面用到的激励函数是线性函数，那么这些层层之间都是线性函数的一个组合，最终整个网络依然是线性的，可以用一个矩阵来代替，跟只有一层网络是没有区别的，所以线性激励函数的表达能力是有限的，不能描述现实生活中存在的大部分的问题，故我们采用非线性的激励函数。 例如一个神经元对猫的眼睛敏感，那当它看到猫的眼睛的时候，就被激励了，相应的参数就会被调优，它的贡献就会越大。下面是几种常见的激活函数，x轴表示传递过来的值，y轴表示它传递出去的值。 图5激励函数 激励函数在预测层，判断哪些值要被送到预测结果那里： 图6 对于激励函数的理解：https://blog.csdn.net/hyman_yx/article/details/51789186  神经层添加神经网络有很多层，那么神经层是如何添加的呢？关于更详细的理论请自行查阅吧，笔者接下来直接上代码。 输入参数有 inputs, in_size, out_size, 和 activation_function。具体实现代码如下。1234567891011121314#添加层def add_layer(inputs, in_size, out_size, activation_function=None): #线性模型 Weights = tf.Variable(tf.random_normal([in_size, out_size])) biases = tf.Variable(tf.zeros([1, out_size]) + 0.1) Wx_plus_b = tf.matmul(inputs, Weights) + biases if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b) return outputs 好了，看完整的代码吧。 【代码参看附件test1_build_network.py】123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import tensorflow as tfimport numpy as np#添加层def add_layer(inputs, in_size, out_size, activation_function=None): #线性模型 Weights = tf.Variable(tf.random_normal([in_size, out_size])) biases = tf.Variable(tf.zeros([1, out_size]) + 0.1) Wx_plus_b = tf.matmul(inputs, Weights) + biases if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b) return outputs#【1】创建原始数据，及要训练的数据x_data = np.linspace(-1,1,300)[:, np.newaxis]noise = np.random.normal(0, 0.05, x_data.shape)y_data = np.square(x_data) - 0.5 + noise#【2】定义节点准备接收数据xs = tf.placeholder(tf.float32, [None, 1])ys = tf.placeholder(tf.float32, [None, 1])#【3】定义神经层：隐藏层和预测层#添加隐藏层，输入值是 xs，在隐藏层有 10 个神经元 l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)#添加输出层，输入值是隐藏层 l1，在预测层输出 1 个结果prediction = add_layer(l1, 10, 1, activation_function=None)#【4】定义损失函数，误差的均方差loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1]))#【5】选择 optimizer 使 loss 达到最小，选择梯度下降的方法训练数据train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)#【6】初始化数据，tf 的必备步骤，主要声明了变量，就必须初始化才能用init = tf.initialize_all_variables()#【7】创建Session会话。启动图sess = tf.Session()#上面定义的都没有运算，直到 sess.run 才会开始运算sess.run(init)#【8】训练模型的到结果，迭代，反复执行上面的最小化损失函数这一操作，拟合数据for i in range(1000): #train_step 和 loss 都是由 placeholder 定义的运算，所以这里要用 feed 传入参数 sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;) if i % 50 == 0: # to see the step improvement print(sess.run(loss, feed_dict=&#123;xs: x_data, ys: y_data&#125;)) 运行结果：12345678910111213141516171819200.70166410.0205323250.0128874320.0206285960.0168251430.00703448940.00585459960.00542544850.00518400180.0050229360.00495063230.0050705460.0060973320.0114961620.0102515110.00560097680.0045459930.00432146850.0042669320.004239731 在前文中，我们成功搭建了一个线性模型，出来的结果都是数据，是不是很抽象呢，笔者也觉得，那么有没有可视化的工具呢，当然有啦，你首先的安装matplotlib包。笔者用的是Anaconda 集成开发工具，你只需在Anaconda Navigator下的TensorFlow中安装matplotlib包即可。 图7安装matplotlib matplotlib 可视化 构建图形，用散点图描述真实数据之间的关系。显示原始数据的散点图代码如下。12345# plot the real datafig = plt.figure()ax = fig.add_subplot(1,1,1)ax.scatter(x_data, y_data)plt.show() 散点图的结果为： 图8散点图结果 接下来，我们来显示预测数据。每隔50次训练刷新一次图形，用红色、宽度为5的线来显示我们的预测数据和输入之间的关系，并暂停0.1s。12345678910111213for i in range(1000): # training sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;) if i % 50 == 0: # to visualize the result and improvement try: ax.lines.remove(lines[0]) except Exception: passprediction_value = sess.run(prediction, feed_dict=&#123;xs: x_data&#125;)# plot the predictionlines = ax.plot(x_data, prediction_value, &apos;r-&apos;, lw=5)plt.pause(0.1) 完整代码如下：【代码参考附件test2_plut_result.py】123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt#需要安装才可使用#添加层def add_layer(inputs, in_size, out_size, activation_function=None): #线性模型 Weights = tf.Variable(tf.random_normal([in_size, out_size])) biases = tf.Variable(tf.zeros([1, out_size]) + 0.1) Wx_plus_b = tf.matmul(inputs, Weights) + biases if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b) return outputs#【1】创建原始数据，及要训练的数据x_data = np.linspace(-1,1,300)[:, np.newaxis]noise = np.random.normal(0, 0.05, x_data.shape)y_data = np.square(x_data) - 0.5 + noise#【2】定义节点准备接收数据xs = tf.placeholder(tf.float32, [None, 1])ys = tf.placeholder(tf.float32, [None, 1])#【3】定义神经层：隐藏层和预测层#添加隐藏层，输入值是 xs，在隐藏层有 10 个神经元 l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)#添加输出层，输入值是隐藏层 l1，在预测层输出 1 个结果prediction = add_layer(l1, 10, 1, activation_function=None)#【4】定义损失函数，误差的均方差loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1]))#【5】选择 optimizer 使 loss 达到最小，选择梯度下降的方法训练数据train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)#【6】初始化数据，tf 的必备步骤，主要声明了变量，就必须初始化才能用init = tf.initialize_all_variables()#【7】创建Session会话。启动图sess = tf.Session()#上面定义的都没有运算，直到 sess.run 才会开始运算sess.run(init)# 打印数据fig = plt.figure()ax = fig.add_subplot(1,1,1)ax.scatter(x_data, y_data)plt.ion()plt.show()#若预测曲线出不来请将其注释#【8】训练模型的到结果，迭代，反复执行上面的最小化损失函数这一操作，拟合数据for i in range(1000): #train_step 和 loss 都是由 placeholder 定义的运算，所以这里要用 feed 传入参数 sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;) if i % 50 == 0: # to visualize the result and improvement try: ax.lines.remove[lines[0]] except Exception: passprediction_value = sess.run(prediction, feed_dict=&#123;xs: x_data&#125;)# plot the predictionlines = ax.plot(x_data, prediction_value, &apos;r-&apos;, lw=5)plt.pause(0.1) 结果如下如所示。 图9 可以看出实际数据和拟合数据有些出入，这就是overfitting的问题，也就是过度拟合问题，在TensorFlow中，有一个很好的工具, 叫做dropout, 只需要给予它一个不被 drop 掉的百分比，就能很好地降低 overfitting。关于Dropout的使用笔者会在后文介绍。 注意对于隐藏层，将激活函数换成 tanh，得到的鱼刺曲线将会更加平滑。当然有兴趣的朋友可以换成其他激活函数。1l1 = add_layer(xs, 1, 10, activation_function=tf.nn.tanh) 图10 tanh激活函数 4.3保存和加载训练好了一个神经网络后，可以保存起来下次使用时再次加载。不管是保存还是加载，都需要初始化一个保存变量。1saver = tf.train.Saver()  保存数据1save_path = saver.save(sess, &quot;my_net/save_net.ckpt&quot;) 【完整代码参看附件test3_1_saver_save.py】12345678910111213141516import tensorflow as tf# 建立神经网络当中的 W 和 b, 并初始化变量.W = tf.Variable([[1,2,3],[3,4,5]], dtype=tf.float32, name=&apos;weights&apos;)b = tf.Variable([[1,2,3]], dtype=tf.float32, name=&apos;biases&apos;)#init= tf.initialize_all_variables()#新版的已经废弃init = tf.global_variables_initializer()saver = tf.train.Saver()# 建立一个 tf.train.Saver() 用来保存, 提取变量. 再创建一个名为my_net的文件夹, # 用这个 saver 来保存变量到这个目录 &quot;my_net/save_net.ckpt&quot;.with tf.Session() as sess: sess.run(init) save_path = saver.save(sess, &quot;my_net/save_net.ckpt&quot;) print(&quot;Save to path: &quot;, save_path) 成功运行后，会生成下文件。 图11 接下来就是加载已经保存的数据及模型了。 【注意】在上面保存完了模型之后。应该把 kernel restart 之后才能使用下面的模型导入。否则会因为两次命名 “v1” 而导致名字错误。 图12  加载数据 1saver.restore(sess, &quot;my_net/save_net.ckpt&quot;) 【完整代码参看附件test3_2_saver_save.py】1234567891011121314import tensorflow as tfimport numpy as np# 建立零时的W 和 b容器. 找到文件目录, 并用saver.restore()我们放在这个目录的变量.W = tf.Variable(np.arange(6).reshape((2, 3)), dtype=tf.float32, name=&quot;weights&quot;)b = tf.Variable(np.arange(3).reshape((1, 3)), dtype=tf.float32, name=&quot;biases&quot;)# not need init stepsaver = tf.train.Saver()# 用 saver 从路径中将 save_net.ckpt 保存的 W 和 b restore 进来with tf.Session() as sess: saver.restore(sess, &quot;my_net/save_net.ckpt&quot;) print(&quot;weights:&quot;, sess.run(W)) print(&quot;biases:&quot;, sess.run(b)) Tensorflow 现在只能保存 variables，还不能保存整个神经网络的框架，所以再使用的时候，需要重新定义框架，然后把 variables 放进去学习。 本章中TensorFlow中API版本容错12#writer = tf.train.SummaryWriter(&quot;logs/&quot;, sess.graph)#新版的TensorFlow已经弃用writer = tf.summary.FileWriter(&quot;logs/&quot;,sess.graph)#加载文件 12#tf.histogram_summary(layer_name + &apos;/weights&apos;, Weights)#新版已经废弃tf.summary.histogram(layer_name + &apos;/weights&apos;, Weights) 12#tf.scalar_summary(&apos;loss&apos;, loss)#新版已经废弃tf.summary.scalar(&apos;loss&apos;, loss) 12#merged = tf.merge_all_summaries()#新版已经废弃merged = tf.summary.merge_all() 本章参考代码点击进入]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《人工智能-TensorFlow开发笔记》第3章 TensorFlow入门]]></title>
    <url>%2F2018%2F12%2F05%2FTensorFlow%2F%E7%AC%AC3%E7%AB%A0%20TensorFlow%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[3.1综述TensorFlow是一个编程系统，使用图来表示计算任务，图中的节点被称之为op（operation的缩写），一个op获得0个或者多个tensor，执行计算，产生0个或多个tensor。每个tensor是一个类型化的多维数组。例如，你可以将一组图像素集表示为一个四维浮点数数组，这四个维度分别是[batch, height, width, channels]。 一个TensorFlow图描述了计算的过程，为了进行计算，图必须在会话里被启动，会话将图的op分发到诸如CPU或GPU之类的设备上，同时提供执行op的方法，这些方法执行后，将产生的tensor返回。在python语言中，返回的tensor是numpy ndarry对象；在C/C++语言中，返回的是tensor是tensorflow::Tensor实例。 3.2计算图通常，TensorFlow 编程可按两个阶段组织起来: 构建阶段和执行阶段; 前者用于组织计算图，而后者利用 session 中执行计算图中的 op 操作。例如, 在构建阶段创建一个图来表示和训练神经网络，然后在执行阶段反复执行一组 op 来实现图中的训练。 TensorFlow 支持 C++、 Python 、Go、Java等编程语言。目前, TensorFlow 的 Python 库更加易用, 它提供了大量的辅助函数来简化构建图的工作, 而这些函数在 C 和 C++ 库中尚不被支持。这三种语言的会话库 (session libraries) 是一致的。  构建计算图刚开始基于 op(source op) 建立图的时候一般不需要任何的输入源 (source op)，例如输入常量(Constance)，再将它们传递给其它 op 执行运算。Python 库中的 op 构造函数返回代表已被组织好的 op 作为输出对象，这些对象可以传递给其它 op 构造函数作为输入。 TensorFlow Python库中有一个默认图(default graph)，op构造器可以为其增加节点。这个默认图对许多程序来说已经足够用了，可以阅读Graph类文档，来了解如何管理多个视图。1234567891011import tensorflow as tf# 创建一个常量op， 产生一个1x2矩阵，这个op被作为一个节点# 加到默认视图中# 构造器的返回值代表该常量op的返回值matrix1 = tf.constant([[3., 3.]])# 创建另一个常量op, 产生一个2x1的矩阵matrix2 = tf.constant([[2.], [2.]])# 创建一个矩阵乘法matmul op，把matrix1和matrix2作为输入：product = tf.matmul(matrix1, matrix2) 默认图现在拥有三个节点，两个constant() op，一个matmul() op. 为了真正进行矩阵乘法运算，得到乘法结果, 你必须在一个会话 (session) 中载入动这个图。  在会话中载入图构建过程完成后就可运行执行过程。为了载入之前所构建的图，必须先创建一个会话对象 (Session object)。会话构建器在未指明参数时会载入默认的图。 完整的会话 API 资料，请参见会话类 Session object 。1234567891011121314151617# 启动默认图sess = tf.Session()# 调用sess的&apos;run()&apos; 方法来执行矩阵乘法op，传入&apos;product&apos;作为该方法的参数# 上面提到，&apos;product&apos;代表了矩阵乘法op的输出，传入它是向方法表明，我们希望取回# 矩阵乘法op的输出。##整个执行过程是自动化的，会话负责传递op所需的全部输入。op通常是并发执行的。## 函数调用&apos;run(product)&apos; 触发了图中三个op（两个常量op和一个矩阵乘法op）的执行。# 返回值&apos;result&apos;是一个numpy &apos;ndarray&apos;对象。result = sess.run(product)print result# ==&gt;[[12.]]# 完成任务，关闭会话sess.close() 会话在完成后必须关闭以释放资源。你也可以使用”with”句块开始一个会话，该会话将在”with”句块结束时自动关闭。123with tf.Session() as sess: result = sess.run([product]) print result TensorFlow 事实上通过一个“翻译”过程，将定义的图转化为不同的可用计算资源间实现分布计算的操作，如 CPU 或是显卡 GPU。通常不需要用户指定具体使用的 CPU或 GPU， TensorFlow 能自动检测并尽可能的充分利用找到的第一个 GPU 进行运算。如果你的设备上有不止一个 GPU，你需要明确指定 op 操作到不同的运算设备以调用它们。使用with…Device语句明确指定哪个 CPU 或 GPU 将被调用: 12345with tf.Session() as sess: with tf.device(&quot;/gpu:1&quot;): matrix1 = tf.constant([[3., 3.]]) matrix2 = tf.constant([[2.], [2.]]) product = tf.matmul(matrix1, matrix2) 使用字符串指定设备，目前支持的设备包括:“/cpu:0”：计算机的 CPU；“/gpu:0”：计算机的第一个 GPU，如果可用；“/gpu:1”：计算机的第二个 GPU，以此类推。关于使用 GPU 的更多信息，请参阅 GPU 使用。现在我们来总结一下前面的例子，完整代码如下。【代码参见附件test1_session.py】12345678910111213141516import tensorflow as tfmatrix1 = tf.constant([[3, 3]])matrix2 = tf.constant([[2],[2]])product = tf.matmul(matrix1, matrix2) # matrix multiply np.dot(m1, m2)# method 1sess = tf.Session()result = sess.run(product)print(result)sess.close()# method 2with tf.Session() as sess: result2 = sess.run(product) print(result2) 3.3交互式使用文档中的python示例使用一个会话Session来启动图，并调用Session.run()方法执行操作。为了便于使用诸如IPython之类的python交互环境，可以使用InteractiveSession代替Session类，使用Tensor.eval()和Operation.run()方法代替Session.run()。这样可以避免使用一个变量来持有会话. 【代码参见附件test2_ InteractiveSession.py】12345678910111213141516import tensorflow as tfsess = tf.InteractiveSession()x = tf.Variable([1.0, 2.0])a = tf.constant([3.0, 3.0]);# 使用初始化器initializer op的run()方法初始化xx.initializer.run()# 增加一个减法sub op，从x减去a。运行减法op，输出结果sub = tf.subtract(x,a)#sub = tf.sub(x,a)#最新的TensorFlow已经弃用tf.subprint(sub.eval())#print#[-2. -1.] 3.4张量(Tensors)TensorFlow 程序使用 tensor数据结构来代表所有的数据，计算图中，操作间传递的数据都是 tensor. 你可以把 TensorFlow 的张量看作是一个 n 维的数组或列表。 一个 tensor包含一个静态类型 rank，和一个 shape。想了解 TensorFlow 是如何处理这些概念的, 参见Rank, Shape，和 Type]。 在 Tensorflow 系统中，张量的维数被描述为阶，但是张量的阶和矩阵的阶并不是同一个概念。张量的阶是张量维数的一个数量描述，下面的张量（使用 python 中 list 定义的）就是 2 阶：t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]你可以认为一个二阶张量就是我们平常所说的矩阵，一阶张量可以认为是一个向量。对于一个二阶张量，你可以使用语句 t[i, j] 来访问其中的任何元素，而对于三阶张量你可以通过 t[i, j, k] 来访问任何元素。 表1张量的阶 ![这里写图片描述](第3章 TensorFlow入门/表1.png) Tensorflow 文档中使用了三种记号来方便地描述张量的维度：阶，形状以及维数。以下展示了它们之间的关系： 表2张量的形状 ![这里写图片描述](第3章 TensorFlow入门/表2.png) 除了维度，tensor 有一个数据类型属性。你可以为一个张量指定下列数据类型中的任意一个类型。 表3 Data Type（数据类型） ![这里写图片描述](第3章 TensorFlow入门/表3.png) 好了，上面介绍了Tensor的相关概念，接下来，笔者带领大家生成tensor的方法。 ① tf.zeros(shape, dtype=tf.float32, name=None) #tf.zeros([2, 3], int32) ==> [[0, 0, 0], [0, 0, 0]] ② tf.ones(shape, dtype=tf.float32, name=None) #tf.ones([2, 3], int32) ==> [[1, 1, 1], [1, 1, 1]] ③ tf.zeros_like(tensor, dtype=None, name=None) 新建一个与给定的 tensor 类型大小一致的 tensor，其所有元素为 1。 # 'tensor' is [[1, 2, 3], [4, 5, 6]] tf.ones_like(tensor) ==> [[1, 1, 1], [1, 1, 1]] ④ tf.constant(value, dtype=None, shape=None, name=’Const’) 创建一个常量 tensor，先给出 value，可以设定其 shape： # Constant 1-D Tensor populated with value list. tensor = tf.constant([1, 2, 3, 4, 5, 6, 7]) => [1 2 3 4 5 6 7] # Constant 2-D tensor populated with scalar value -1. tensor = tf.constant(-1.0, shape=[2, 3]) => [[-1. -1. -1.] [-1. -1. -1.] ⑤ tf.fill(dims, value, name=None) 创建一个形状大小为 dim 的 tensor，其初始值为 value # Output tensor has shape [2, 3]. fill([2, 3], 9) ==> [[9, 9, 9],[9, 9, 9]] ⑥ tf.ones_like(tensor, dtype=None, name=None) 在tensorflow程序中所有的数据都通过张量的形式来表示。从功能的角度看，张量可以被理解为多维数组。其中零阶张量表示标量（scalar）也就是一个数；一阶张量为向量，也就是一维数组；n阶张量可以理解为一个n维数组。但张量的实现并不是直接采用数组的形式，它只是对TensorFlow中运算结果的引用。 在张量中并没有保存数字，它保存的是如何得到这些数字的计算过程。 如下代码，并不会得到加法的结果，而会得到对结果的一个引用。 【代码参见附件test3_tensor.py】 1234567891011import tensorflow as tf# 创建两个变量a=tf.constant([1.0,2.0],name=&apos;a&apos;)b=tf.constant([2.0,3.0],name=&apos;b&apos;)result=tf.add(a,b,name=&apos;add&apos;)print(result)#print#Tensor(“add:0”, shape=(2,), dtype=float32) 从上面的代码可以看出TensorFlow中的张量和NumPy中的数组不同，TensorFlow计算的姐结果不是一个具体的数字，而是一个张亮结构。从上面代码运行的结果可以看出，一个张量主要保存三个属性：名字（name）、维度（shape）和类型（type）。 张量的第一个属性名字不仅是一个张量的唯一标识符，它同样也给出出了这个张量是如何计算出来的。TensorFlow的计算可以通过计算图的模型来建立，而计算图上的每个节点代表了一个计算，计算的结果就保存在张量之中。所以张量和计算图上的节点所代表的计算结果是对应的。这样张量的命名就可以通过“node:str_output”的形式来给出。其中node为节点的名称，str_output表示当前张量来自节点的第几个输出。比如上面代码打出来的“add:0”就说明result这个张量是计算节点”add”输出的第一个结果(编号从零开始)。 张量的的第二个属性是张量的维度(shape)。这个属性描述了一个张量的维度信息。张量的第三个属性是类型（type），每个张量会有唯一的类型。TensorFlow会对参与运算的所有张量进行类型检查，当发现类型不匹配时会报错。 张量的使用可以总结为两大类。第一类用途是对中间计算结果的引用。当一个计算包含很多计算结果时，使用张量可以很大的提高代码可读性。一下为使用张量和不使用张量记录中间结果来完成向量相加的代码对比。 123456789import tensorflow as tf#使用张量记录中间结果a=tf.constant([1.0,2.0],name=&apos;a&apos;)b=tf.constant([2.0,3.0],name=&apos;b&apos;)result=a+b#直接结算result=tf.constant([1.0,2.0],name=&apos;a&apos;)+tf.constant([2.0,3.0],name=&apos;b&apos;) 从上面的程序样例可以看到a和b其实就是对常量生成这个运算结果的引用，这样在做加法时可以直接使用这两个变量，而不需要再去生成这些常量。同时通过张量来存储中间结果，这样可以很方便的获取中间结果。比如在卷积神经网络中，卷积层或者池化层有可能改变张量的维度，通过result.get_shape函数来获取结果张量的维度信息可以免去人工计算的麻烦。 张量的第二类情况是当计算图构造完成之后，张量可以来获得计算结果，也就是得到真实的数字。虽然张量本身没有存储具体的数字，但可以通过会话session得到这些具体的数字。比如使用tf.Session().run(result)语句来得到计算结果。 ## 3.5变量(Variables) 变量维持了图执行过程中的状态信息。下面的例子演示了如何使用变量实现一个简单的计数器，更多细节详见[变量](http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/variables/index.html)章节。 【代码参见附件test4_variables.py】 123456789101112131415161718192021222324import tensorflow as tf# 创建一个变量，初始为标量0state = tf.Variable(0, name=&quot;counter&quot;)# 创建一个op，其作用是使`state`增加1one = tf.constant(1)new_value = tf.add(state, one)update = tf.assign(state, new_value)# 启动图后，变量必须先经过init op初始化# 首先先增加一个初始化op到图中init_op = tf.initialize_all_variables()# 启动图with tf.Session() as sess: # 运行init op sess.run(init_op) # 打印 state 的初始值 print(sess.run(state)) # 运行op， 更新state 并打印 for _ in range(3): sess.run(update) print(sess.run(state)) 输出结果： 1234# 0# 1# 2# 3 代码中assign()操作是图所描述的表达式的一部分，正如add()操作一样，所以在调用run()执行表达式之前，它并不会真正执行赋值操作。 通常会将一个统计模型中的参数表示为一组变量。例如，你可以将一个神经网络的权重作为某个变量存储在一个tensor中。在训练过程中，通过反复训练图，更新这个tensor。 ## 3.6取回(Fetches ) 为了取回操作的输出内容, 可以在使用 Session 对象的 run() 调用执行图时，传入一些 tensor, 这些 tensor 会帮助你取回结果. 在之前的例子里, 我们只取回了单个节点state，但是你也可以取回多个 tensor。对于了解C语言的朋友来说，这个就如同函数的方返回值，在前文中对取回(Fetches)有所使用，在这里只是单独讲解而已。 【代码参考附件test5_fetches.py】 123456789101112131415import tensorflow as tfinput1 = tf.constant(3.0)input2 = tf.constant(4.0)input3 = tf.constant(5.0)intermed = tf.add(input2, input3)mul = tf.multiply(input1, intermed)#mul = tf.mul(input1, intermed)#最新的TensorFlow已经tf.mul请读者朋友注意咯with tf.Session() as sess: result = sess.run([mul, intermed])print(result)# print# [27.0, 9.0] 需要获取的多个 tensor 值，在 op 的一次运行中一起获得（而不是逐个去获取 tensor）。 ## 3.7供给(Feeds ) 上述示例在计算图中引入了 tensor，以 常量 (Constants) 或 变量 (Variables) 的形式存储。TensorFlow 还提供给 (feed) 机制，该机制可临时替代图中的任意操作中的 tensor可以对图中任何操作提交补丁, 直接插入一个 tensor。 feed 使用一个 tensor 值临时替换一个操作的输出结果。你可以提供 feed 数据作为run() 调用的参数。feed 只在调用它的方法内有效，方法结束，feed 就会消失. 最常见的用例是将某些特殊的操作指定为"feed" 操作，标记的方法是使用tf.placeholder()为这些操作创建占位符。 【代码参考附件test6_fdeed.py】 1234567891011import tensorflow as tfinput1 = tf.placeholder(tf.float32)input2 = tf.placeholder(tf.float32)ouput = tf.multiply(input1, input2)#ouput = tf.mul(input1, input2)#最新的TensorFlow已经tf.mul请读者朋友注意咯with tf.Session() as sess: print(sess.run(ouput, feed_dict=&#123;input1: [7.], input2: [2.]&#125;))# print# [ 14.] ## 3.8总结-线性模型实例 看到这里，笔者相信很多朋友都还是云里雾里，不知所云，前面只是TensorFlow的基本概念，接下来笔者带领大家来看一个线性模型实例，看完这个例子，我相信你对TensorFlow的模型建立就很清晰了，好了，废话不说，我们开始吧。 Tensorflow编程包含两个步骤：构造计算图；运行计算图。 **第一步：构建计算图** 构造一个简单的计算图：每个节点将0或多个tensor作为输入，输出一个tensor。一种类型的节点是常量节点constant，就如同tensorflow中的常数，它有0个输入，输出一个值。 构建两个浮点型tensor：node1和node2 123node1 = tf.constant(3.0, tf.float32) node2 = tf.constant(4.0) # also tf.float32 implicitly print(node1, node2) 输出结果： 1Tensor(&quot;Const:0&quot;, shape=(), dtype=float32) Tensor(&quot;Const_1:0&quot;, shape=(), dtype=float32) 可以看出，打印结果并不是我们期待的3.0 , 4.0，因为这是打印的节点（属于计算操作），当评估运行之后，才是我们期待的值。评估一个节点，必须在一个会话Session中运行计算图，会话封装了Tensorflow运行时的状态和控制。 **第二步：创建会话Session对象** 接下来创建一个Session会话对象，调用run方法，运行计算图，去评估node1和node2。 123sess=tf.Session() result = sess.run([node1,node2])print(result) 输出结果： 1[3.0, 4.0] 到这里，一个最基本的TensorFlow模型就就已经建好了，对于以上模型是最基本TensorFlow代码，就像学习C语言的Hello World。接下来我们将创建更加复杂的模型，也就是一个大家最常见的线性模型优化。 我们知道，使用计算操作将多个节点组合，以此构建更复杂的计算，例如将两个常量节点相加，产生一个新的计算图： 1234node3 = tf.add(node1, node2) result = sess.run(node3)print(&quot;node3: &quot;, node3) print(&quot;sess.run(node3): &quot;,result) 输出结果： 12node3: Tensor(&quot;Add:0&quot;, shape=(), dtype=float32)sess.run(node3): 7.0 Tensorflow提供了一个名为TensorBoard的部分，可以以图片的方式展示计算图。 ![这里写图片描述](第3章 TensorFlow入门/图1.png) 图1 这个计算图不是特别有趣，因为它产生的是一个常量结果。计算图可以使用占位符placeholder参数化的从外部输入数据，placeholder的作用是在稍后提供一个值，也就是前文提及的供给(Feeds )。12345678# 构造计算图 a=tf.placeholder(tf.float32) b=tf.placeholder(tf.float32) adder_node=a+b #运行计算图 print(&quot;adder_node:&quot;,adder_node) print(sess.run(adder_node,&#123;a:3,b:4.5&#125;)) print(sess.run(adder_node,&#123;a:[1,3],b:[2,4]&#125;)) 输出结果：123adder_node: Tensor(&quot;add:0&quot;, dtype=float32) 7.5 [ 3. 7.] 我们可以添加一个操作，使计算图更加复杂：123add_and_triple=adder_node * 3 print(&quot;add_and_triple:&quot;,add_and_triple) print(&quot;sess run result:&quot;,sess.run(add_and_triple,&#123;a:3,b:4.5&#125;)) 输出结果：12add_and_triple: Tensor(&quot;mul:0&quot;, dtype=float32) sess run result: 22.5 在机器学习中，需要模型可以任意输入，为了模型具有可训练能力，需要修正计算图，使对于同样的输入得到新的输出。变量Variable允许我们为计算图添加训练参数。构造一个变量，需要提供类型和初始值：1234W=tf.Variable([.3],tf.float32) b=tf.Variable([-.3],tf.float32) x=tf.placeholder(tf.float32) linear_model=W*x+b 常量节点在调用tf.constant时就被初始化，而变量在调用tf.Variable时并不初始化，必须显性的执行如下操作：12init = tf.global_variables_initializer() sess.run(init) 意识到init对象是Tensorflow子图初始化所有全局变量的句柄是重要的，在调用sess.run(init)方法之前，所有变量都是未初始化的。因为x是一个占位符，我们可以指定几个值来评估linear_model模型（训练），运行计算图：12print(&quot;linear_model:&quot;,linear_model) print(sess.run(linear_model,&#123;x:[1,2,3,4]&#125;)) 输出结果：12linear_model: Tensor(&quot;add_1:0&quot;, dtype=float32) [ 0. 0.30000001 0.60000002 0.90000004] 我们创建了一个模型，但是不知道这个模型的效果怎么样，基于训练数据来评估模型，还需要一个placeholder y 来提供期望值，我们需要一个损失函数loss function。损失函数测量当前模型与真实数据之间的差距，对于线性模型，我们使用标准损失函数，求模型预测结果与实际数据之间差值的平方和sum the squares of the deltas。linear_model - y 构造了一个向量，对应每个元素的差值，我们调用tf.square求平方，使用tf.reduce_sum求和所有的平方差为一个标量scalar。12345y=tf.placeholder(tf.float32) squared_deltas=tf.square(linear_model-y) loss=tf.reduce_sum(squared_deltas) print(&quot;loss:&quot;,loss) print(sess.run(loss,&#123;x:[1,2,3,4],y:[0,-1,-2,-3]&#125;)) 输出结果：12loss: Tensor(&quot;Sum:0&quot;, dtype=float32) 23.66 我们可以通过手动的方式将参数W和b置为W=-1，b=1，使模型最优，即损失函数最小。初始化后的变量可以通过tf.assign来更改，tf.assign后需要tf.run生效1234fixW=tf.assign(W,[-1.]) fixb=tf.assign(b,[1.]) sess.run([fixW,fixb]) print(&quot;fix loss:&quot;,sess.run(loss,&#123;x:[1,2,3,4],y:[0,-1,-2,-3]&#125;)) 输出结果：1fix loss: 0.0 我们猜想最优的W和b值，但是在机器学习中，就是自动的寻找这些最优的模型参数。Tensorflow提供了优化器Optimizer慢慢改变每个变量来最小化损失函数。最简单的Optimizer是梯度下降gradient descent，它根据损失函数相对于该变量的导数大小来修改参数值，一般来讲，手动计算导数是乏味且易出错的，Tensorflow可以使用方法tf.gradients自动的为给定模型计算导数。优化器通常做这个工作。1234567optimizer=tf.train.GradientDescentOptimizer(0.01) train=optimizer.minimize(loss) print(&quot;train:\n&quot;,trian) sess.run(init)#重置变量到初始化值 for i in range(1000): sess.run(train,&#123;x:[1,2,3,4],y:[0,-1,-2,-3]&#125;) print(sess.run([W,b])) 输出结果：1234train: name: &quot;GradientDescent&quot; op: &quot;NoOp&quot; [array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)] 到此，我们实现了一次真实的机器学习，尽管我们只实现的是简单的线下回归，不需要多少Tensorflow core代码，然而复杂的模型和方法输入数据会需要更多的代码量，因此Tensorflow对于一般的模式、结构和功能提供了高级别的抽象。 好了，笔者对以上代码优化，完整代码如下。【代码参考附件full_code.py】123456789101112131415161718192021222324252627282930313233343536373839import tensorflow as tfimport numpy as np#【第一步】准备数据#创建原始数据,使用 NumPy 生成假数据(phony data), 总共 100 个点x_data = np.random.rand(100).astype(np.float32)y_data = x_data*0.6 + 0.6#【第二步】构造线性模型Weights = tf.Variable(tf.random_uniform([1], -1.0, 1.0))biases = tf.Variable(tf.zeros([1]))y = Weights*x_data + biases#【第三步】求解模型#定义损失函数，误差的均方差loss = tf.reduce_mean(tf.square(y-y_data))# 选择梯度下降的方法optimizer = tf.train.GradientDescentOptimizer(0.5)# 迭代的目标：最小化损失函数train = optimizer.minimize(loss)#【第四步】初始化数据，tf 的必备步骤，主要声明了变量，就必须初始化才能用init = tf.initialize_all_variables()# 设置tensorflow对GPU的使用按需分配，配置好GPU才能使用以下两行代码#config = tf.ConfigProto()#config.gpu_options.allow_growth = True#【第五步】创建Session会话。启动图sess = tf.Session()#sess = tf.Session(config = config)配置好GPU才能使用以下代码sess.run(init) #【第六步】训练模型的到结果，迭代，反复执行上面的最小化损失函数这一操作（train op）,拟合平面for step in range(201): sess.run(train) if step % 20 == 0: print(step, sess.run(Weights), sess.run(biases)) 输出结果：12345678910110 [0.45143753] [0.9062223]20 [0.54057676] [0.6306117]40 [0.5854129] [0.6075145]60 [0.5964192] [0.60184467]80 [0.59912103] [0.60045284]100 [0.5997842] [0.60011125]120 [0.599947] [0.6000273]140 [0.59998703] [0.6000067]160 [0.5999968] [0.6000017]180 [0.5999992] [0.60000044]200 [0.59999967] [0.6000002] 参考TensorFlow中文手册 本章参考代码点击进入]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《人工智能-TensorFlow开发笔记》 第1章 TensorFlow简介]]></title>
    <url>%2F2018%2F12%2F05%2FTensorFlow%2F%E7%AC%AC1%E7%AB%A0%20TensorFlow%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[TensorFlow是一个开源软件库，用于各种感知和语言理解任务的机器学习。目前被50个团队用于研究和生产许多Google商业产品，如语音识别、Gmail、Google 相册和搜索，其中许多产品曾使用过其前任软件DistBelief。TensorFlow最初由Google Brain团队开发，用于Google的研究和生产，于2015年11月9日在Apache 2.0开源许可证下发布。  什么是TensorFlow？TensorFlow是Google开源的第二代用于数字计算（numerical computation）的软件库。它是基于数据流图的处理框架，图中的节点表示数学运算（mathematical operations），边表示运算节点之间的数据交互。TensorFlow从字面意义上来讲有两层含义，一个是Tensor，它代表的是节点之间传递的数据，通常这个数据是一个多维度矩阵（multidimensional data arrays）或者一维向量；第二层意思Flow,指的是数据流，形象理解就是数据按照流的形式进入数据运算图的各个节点。 与Caffe、Theano、Torch、MXNet等框架相比，TensorFlow在Github上Fork数和Star数都是最多的，而且在图形分类、音频处理、推荐系统和自然语言处理等场景下都有丰富的应用。最近流行的Keras框架底层默认使用TensorFlow，著名的斯坦福CS231n课程使用TensorFlow作为授课和作业的编程语言，国内外多本TensorFlow书籍已经在筹备或者发售中，AlphaGo开发团队Deepmind也计划将神经网络应用迁移到TensorFlow中，这无不印证了TensorFlow在业界的流行程度。 TensorFlow不仅在Github开放了源代码，在《TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems》论文中也介绍了系统框架的设计与实现，其中测试过200节点规模的训练集群也是其他分布式深度学习框架所不能媲美的。Google还在《Wide &amp; Deep Learning for Recommender Systems》和《The YouTube Video Recommendation System》论文中介绍了Google Play应用商店和YouTube视频推荐的算法模型，还提供了基于TensorFlow的代码实例，使用TensorFlow任何人都可以在ImageNet或Kaggle竞赛中得到接近State of the art的好成绩。  TensorFlow特点1.灵活（Deep Flexibility）它不仅是可以用来做神经网络算法研究，也可以用来做普通的机器学习算法，甚至是只要你能够把计算表示成数据流图，都可以用TensorFlow。 2.便携（True Portability）这个工具可以部署在个人PC上，单CPU，多CPU，单GPU，多GPU，单机多GPU，多机多CPU，多机多GPU，Android手机上等，几乎涵盖各种场景的计算设备。 3.研究和产品的桥梁（Connect Research andProduction）在谷歌，研究科学家可以用TensorFlow研究新的算法，产品团队可以用它来训练实际的产品模型，更重要的是这样就更容易将研究成果转化到实际的产品。另外Google在白皮书上说道，几乎所有的产品都用到了TensorFlow，比如搜索排序，语音识别，谷歌相册，自然语言处理等。 4.自动做微分运算（Auto-Differentiation）机器学习中的很多算法都用到了梯度，使用TensorFlow，它将自动帮你求出梯度，只要你定义好目标函数，增加数据就好了。听上去很诱人，暂时不知道具体咋实现的。 5.语言灵活（Language Options）TensorFlow使用C++实现的，然后用Python封装，暂时只支持这两种语言，谷歌号召社区通过SWIG开发更多的语言接口来支持TensorFlow。 6.最大化性能（Maximize Performance）通过对线程，队列和异步计算的支持（first-class support），TensorFlow可以运行在各种硬件上，同时根据计算的需要，合理将运算分配到相应的设备，比如卷积就分配到GPU上。  历史版本 DistBelief从2010年开始，Google Brain建立DistBelief作为他们的第一代专有的机器学习系统。50多个团队在Google和其他Alphabet公司在商业产品部署了DistBelief的深度学习神经网络，包括Google搜索、Google语音搜索、广告、Google 相册、Google地图、Google街景、Google翻译和YouTube。Google指派计算机科学家，如Geoffrey Hinton和Jeff Dean，简化和重构DistBelief的代码库，使其变成一个更快、更健壮的应用级别代码库，形成了TensorFlow。2009年，Hinton领导的研究小组大大减少使用DistBelief的神经网络的错误数量，通过Hinton在广义反向传播的科学突破。最值得注意的是，Hinton的突破直接使Google语音识别软件中的错误减少至少25%。  TensorFlowTensorFlow是Google Brain的第二代机器学习系统。1.0.0版本发布于2017年2月11日。虽然参考实现运行在单台设备，TensorFlow可以运行在多个CPU和GPU（和可选的CUDA扩展和图形处理器通用计算的SYCL扩展）。TensorFlow可用于64位Linux、macOS和Windows，以及移动计算平台，包括Android和iOS。TensorFlow的计算使用有状态的数据流图表示。TensorFlow的名字来源于这类神经网络对多维数组执行的操作。这些多维数组被称为张量。2016年6月，Jeff Dean称在GitHub有1500个库提到了TensorFlow，其中只有5个来自Google。[10]  张量处理单元（TPU）2016年5月，Google宣布了张量处理单元（TPU），一个专为机器学习和TensorFlow定制的ASIC。TPU是一个可编程的AI加速器，提供高吞吐量的低精度计算（如8位），面向使用或运行模型而不是训练模型。Google宣布他们已经在数据中心中运行TPU长达一年多，发现它们对机器学习提供一个数量级更优的每瓦特性能。 2017年5月Google宣布第二代张量处理单元，并在Google Compute Engine中可用。第二代TPU提供最高180 teraflops性能，组装成64个TPU的集群时提供最高11.5 petaflops性能。  TensorFlow Lite2017年5月Google宣布从Android Oreo开始，提供一个专用于Android开发的软件栈TensorFlow Lite。 学习网站TensorFlow中文官网TensorFlow中文论坛TensorFlow中文官方手册TensorFlow源码 【注】TensorFlow官网有需要翻墙，对于新手来说，参考以上网站就够了。]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《人工智能-TensorFlow开发笔记》神经网络架构发展史（CNN）]]></title>
    <url>%2F2018%2F12%2F05%2FTensorFlow%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%8F%91%E5%B1%95%E5%8F%B2%2F</url>
    <content type="text"><![CDATA[笔者主要从事图像的识别与分类研究，在这里笔者值探讨卷积神经的发展史。 1.BP1985年，Rumelhart和Hinton等人提出了后向传播（Back Propagation，BP）算法（也有说1986年的，指的是他们另一篇paper：Learning representations by back-propagating errors)，使得神经网络的训练变得简单可行，这篇文章在Google Scholar上的引用次数达到了19000多次，目前还是比Cortes和Vapnic的Support-Vector Networks稍落后一点，不过以Deep Learning最近的发展劲头来看，超越指日可待。 【注】BP虽然不算卷积神经网络，但它是神经网络的老前辈，学习神经网络不得不知道的一个网络啊。Hinton主页 2.LeNet51988年，LeCun在BP网络的基础上发表了“A theoretical framework for Back-Propagation”几年后，LeCun利用BP算法来训练多层神经网络用于识别手写邮政编码，（论文：Handwritten Digit Recognition: Applications of Neural Net Chips and Automatic Learning）这个工作也可以说是就是CNN的开山之作，多处用到了55的卷积核，但在这篇文章中LeCun只是说把55的相邻区域作为感受野，并未提及卷积或卷积神经网络。在随后很多年，LeCun不断优化，发表了很多关于手写识别的文章。 1994年，word-level training of a handwritten word recognizer based on convolutional neural networks发表，这可以说是最早的卷积神经网络之一， 并且推动了深度学习领域的发展。自从1988年开始，在许多次成功的迭代后，这项由Yann LeCun完成的开拓性成果被命名为LeNet5（参见：Gradient-Based Learning Applied to Document Recognition）. 1998年的LeNet5标注着CNN的真正面世，但是这个模型在后来的一段时间并未能火起来，主要原因是要求机器性能较好，而且其他的算法像SVM也能达到类似的效果甚至超过。 LeNet5的架构基于这样的观点：（尤其是）图像的特征分布在整张图像上，以及带有可学习参数的卷积是一种用少量参数在多个位置上提取相似特征的有效方法。在那时候，没有GPU帮助训练，甚至CPU的速度也很慢。因此，能够保存参数以及计算过程是一个关键的进展。这和将每个像素用作一个大型多层神经网络的单独输入相反。LeNet5阐述了那些像素不应该被使用在第一层，因为图像具有很强的空间相关性，而使用图像中独立的像素作为不同的输入特征则利用不到这些相关性。LeNet5特征能够总结为如下几点： 1）卷积神经网络使用三个层作为一个系列： 卷积，池化，非线性； 2）使用卷积提取空间特征； 3）使用映射到空间均值下采样（subsample）； 4）双曲线（tanh）或S型（sigmoid）形式的非线性； 5）多层神经网络（MLP）作为最后的分类器； 6）层与层之间的稀疏连接矩阵避免大的计算成本。 总体看来，这个网络是最近大量神经网络架构的起点，并且也给这个领域带来了许多灵感。 【注】以上提及的文章均可在LeCun的主页中找到。 LeCun主页LeCun论文下载地址 从1998年到2010年，神经网络处于孵化阶段，大多数人没有意识到他们不断增强的力量，与此同时其他研究者则进展缓慢。由于手机相机以及便宜的数字相机的出现，越来越多的数据可被利用。并且计算能力也在成长，CPU变得更快，GPU变成了多种用途的计算工具。这些趋势使得神经网络有所进展，虽然速度很慢，数据和计算能力使得神经网络能够完成的任务越来越有趣，之后一切变得清晰起来。 3.Dan Ciresan Net2010 年的时候，Dan Claudiu Ciresan 和 Jurgen Schmidhuber 发布了最早的 GPU 神经网络的一个实现。这个实现是在一块 NVIDIA GTX 280 图形处理器上运行 9 层的神经网络，包含前向与反向传播。 2010年Dan Claudiu Ciresan和Jurgen Schmidhuber发表了一个GPU神经网络（Deep Big Simple Neural Nets Excel on Handwritten Digit Recognition）。论文里面证明了使用 NVIDIA GTX 280 GPU之后能够处理高达9层的神经网络。 从此之后，Nvidia公司的股价开始不断攀升，深度学习也越来越为人们所熟知。 论文地址Dan Claudiu Ciresan 地址 4. AlexNet2012年，Alex Krizhevsky发表了AlexNet（参见 ImageNet Classification with Deep Convolutional Neural Networks），它是LeNet的一种更深更宽的版本，并以显著的优势赢得了困难的ImageNet竞赛。 AlexNet是在2012年被发表的一个经典之作，并在当年取得了ImageNet最好的成绩，也是在那年之后，更多的更深的神经网络被提出，其官方提供的数据模型。 AlexNet 将LeNet的思想扩展到了更大的能学习到更复杂的对象层次的神经网络上。这项工作的贡献有： 1）使用修正的非线性单元（ReLU） 2）在训练的时候使用Dropout技术有选择的忽视单个神经元，从而避免过拟合 3）覆盖进行最大池化，避免平均池化的平均化效果。 4）使用GPU NVIDIA GTX580减少训练时间 在那时， GPU比CPU提供更多数量的核，训练时间可以提升10倍。这又反过来允许使用更大的数据集和更大的图像。 AlexNet的成功掀起了一场小革命。卷积神经网络现在是深度学习的骨干。它已经变成了现在能够解决有用任务的大型神经网络的代名词。 Alex Krizhevsky主页及论文下载地址1Alex Krizhevsky主页及论文下载地址2 5.ZF Net2013 ILSVRC比赛冠军，结构相对于AlexNet无太大的变化，只是进行了参数的优化。使用Relu激活函数，交叉熵代价函数。 Matthew D. Zeiler论文下载Rob Fergus主页 6.Overfeat2013年12月， 纽约大学的Yann LeCun实验室提出了AlexNet的衍生—Overfeat（参见： OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks）. 这篇文章也提过了学习边界框（learning bounding box），并导致之后出现了很多研究同一主题的论文。 论文地址 7.VGG-Net2014年，来自牛津大学的VGG网络（参见： Very Deep Convolutional Networks for Large-Scale Image Recognition）是第一个在各个卷积层使用更小的3*3过滤器（filter），并把他们组合成为一个卷积序列进行处理的网络。 这看起来和LeNet的原理相反，即使用大的卷积来获得一张图像中相似的特征。和AlexNet的99或1111过滤器不同，VGG的过滤器很小，离LeNet竭力所要避免的臭名昭著的11的卷积异常接近—至少在该网络的第一层是这样。但是VGG巨大的进展是通过依次采用多个33的卷积，能够模仿出更大的感受野（receptive field）的效果，例如55或77.这些思想也被用在了最近的更多的网络架构上。如Inception与ResNet。VGG网络使用多个33卷积层去表征复杂特征。如果VGG-E的第3，4，5块（block）：256256 和 512512个33过滤器被依次使用多次，以提取更多复杂特征以及这些特征的组合。其效果就等于一个带有3个卷积层的大型的512*512分类器。这显然意味着大量的参数和学习能力。但是这些网络训练困难，必须划分到较小的网络，并逐层累加。这是因为缺少强大的方式对模型进行正则化，这样或多或少约束大量由于大量参数增长的搜索空间。 VGG在许多层中都使用大特征尺寸，因为推断（inference）在运行时是相当耗费时间。正如Inception的瓶颈那样，减少特征的数量将节省一些计算成本。 VGG-Net 在ILSVRC localization and classification 两个问题上分别取得了第一名和第二名，VGG-Net不同于AlexNet的地方是：VGG-Net使用更多的层，通常有16－19层，而AlexNet只有8层。另外一个不同的地方是：VGG-Net的所有 convolutional layer 使用同样大小的 convolutional filter，大小为 3 x 3。 目前VGG有6个版本。 Andrew Zisserman主页Karen Simonyan主页 论文地址1论文地址2 8.NIN网络中的网络（NiN，参见论文： Network in Network）的思路简单又伟大： 使用1*1卷积为卷积层的特征提供更组合型的能力。 NiN架构在各个卷积之后使用空间MLP层，以便更好地在其它层之前组合特征。同样，你可以认为11卷积与LeNet最初的原理相悖，但是事实上他们可以以一种更好的方式组合卷积特征，而这时不可能通过简单的堆叠更多的卷积特征做到的。这和使用原始像素作为下一层输入是有区别的。其中11卷积常常被用于在卷积之后的特征映射上对特征进行空间组合，所以它们实际上可以使用非常少的参数，并在这些特征上的所有像素上共享。 MLP的能力是通过将卷积特征组合到更复杂的组（group）来极大地增强单个卷积特征的有效性。这个想法之后被用到一些最近的框架上，例如ResNet，Inception及其衍生技术。 NiN也使用了平均池化层作为最后分类器的一部分，这是另一种将会变得常见的实践。这是用过在分类之前对网络针对多个输入图像的响应进行平均完成的。 NIN目前有3个版本。 论文地址 9. R-CNN、Fast R-CNN、Faster R-CNNRCNN（Regions with CNN features）是将CNN方法应用到目标检测问题上的一个里程碑，由年轻有为的RBG大神提出，借助CNN良好的特征提取和分类性能，通过RegionProposal方法实现目标检测问题的转化。各个论文均可在Ross Girshick主页找到。 Ross Girshick (rbg)地址论文笔记 源码：R-CNN：https://github.com/rbgirshick/rcnn Fast R-CNN：https://github.com/rbgirshick/fast-rcnnhttps://github.com/rbgirshick/caffe-fast-rcnn Faster R-CNN：https://github.com/chenyuntc/simple-faster-rcnn-pytorchhttps://github.com/YoungGer/Faster-RCNN-Pytorchhttps://github.com/rbgirshick/py-faster-rcnn 10.GoogLeNet来自Google的Christian Szegedy 开始追求减少深度学习网络的计算开销， 并设计出GoogleLeNet-第一个Inception架构。 在2014年秋季，深度学习模型正在变得在图像与视频帧的分类中非常有用。大多数怀疑者已经不再怀疑深度学习与神经网络这一次真的回来了。而且相信这种趋势将一直发展下去。鉴于这些技术的用处，谷歌这样的巨头非常有兴趣在他们的服务器上高效且大规模的部署这些架构。 在2014年ILSVRC挑战赛获得冠军，将Top5 的错误率降低到6.67%. 一个22层的深度网络，论文题目为：Going deeper with convolutions。GoogLeNet这个名字也是挺有意思的，为了像开山鼻祖的LeNet网络致敬，他们选择了这样的名字。 GoogLeNet使用没有Inception模块的主干作为初始层，之后是与NiN相似的一个平均池化层加softmax分类器。这个分类器比AlexNet与VGG的分类器的运算数量少的多。这也促成了一项非常有效的网络设计（参见论文： An Analysis of Deep Neural Network Models for Practical Applications）Christian和他的团队都是非常高产的研究人员。2015年2月，Batch-normalized Inception被引入作为InceptionV2（参见论文： Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift）.Batch-normalization 在一层的输出上计算所有特征映射的均值和标准差，并且使用这些值规范化它们的响应。这相当于数据增白（whitening），因此使得所有的神经图（neural maps）在同样的范围内有响应，而且是零均值。在下一层不需要从输入数据中学习offset时，这有助于训练，还能重点关注如何最好的结合这些特性。 2015年12月， 该团队发布Inception模块和类似架构的一个新版本（参见论文：Rethinking the Inception Architechture for Computer Vision）.该论文更好地解释了原始的GoogLeNet架构，在设计选择上给出了更过的细节。原始思路如下：通过谨慎构建网络，平衡深度与宽度，从而最大化进入网络的信息流。在每次池化之前，增加特征映射。每当深度增加时，网络层的深度或者特征的数量也系统性的增加。使得每一层深度增加之前，先增加特征的结合。一般只使用33的卷积，可能情况下将55和77过滤器分成多个33。 Inception v4也结合了Inception模块和ResNet模块的特性。我认为该架构不太简洁。但也充斥着较少透明度的启发法。很难理解里面的选择，对作者而言也难以解释。考虑到网络的简洁性，可被轻易理解并修正，那ResNet可能就更好了。 目前GoogLeNet有4个版本。 论文地址：[v1] Going Deeper with Convolutions, 6.67% test errorhttp://arxiv.org/abs/1409.4842[v2] Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, 4.8% test errorhttp://arxiv.org/abs/1502.03167[v3] Rethinking the Inception Architecture for Computer Vision, 3.5% test errorhttp://arxiv.org/abs/1512.00567[v4] Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, 3.08% test errorhttp://arxiv.org/abs/1602.07261 11.ResNet2015年12月又出现了新的变革，这和Inception V3出现的时间一样。ResNet有着简单的思路：供给两个连续卷积层的输出，并分流（bypassing）输入进入下一层（参见论文： Deep Residual Learning for Image Recognition）。 这和之前的一些旧思路类似。DanReSNet中，他们分流两个层并被应用于更大的规模。在两层后分流是一个关键的直觉。因为分流一个层并未给出更多的改进。通过两层可能认为是一个小型的分类器，或者一个Network-In-Network。 这是第一个超过100的网络， 甚至还能训练出1000层的网络。 有大量网络层的ResNet开始使用类似于Inception瓶颈层的网络层，这种层通过首先由带有更小输出的11卷积较少特征的数量，然后使用一个33的层，再使用1*1层处理更大量的特征。类似于Inception模块，这样能够保证计算量低，同事提供丰富的特征结合。 ResNet在输入上使用相对简单的初始化层： 一个带有两个池的7*7卷积层。可以把这个与更复杂、更少直觉性的InceptionV3 V4坐下对比。ResNet也是用一个池化层加上softmax作为最后的分类器。 关于ResNet的其他洞见每天都有发生：ResNet可被认为既是平行模块又是连续模块，把输入输出视为在许多模块中并行，同时每个模块的输出又是连续连接的。ResNet也可被视为并行模块或连续模块的多种组合（参见论文： Residual Networks are Exponential Ensembles of Relatively Shallow Networks）。已经发现ResNet通常在20-30层的网络块上以并行的方式运行。而不是连续流过整个网络长度。当ResNet像RNN一样把输出反馈到输入时，该网络可被视为更好的生物上可信的皮质模型（参见论文： Bridging the Gaps between Residual Learning, Recurrent Neural Networks and Visual Cortex）。 论文地址 12.SqueezeNet2016年，SqueezeNet（参见论文： SqueezeNet： AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size）是最近才公布的，该架构对ResNet与Inception里面的概念进行了重新的处理。一个更好的架构设计网络型号要小，而且参数还不需要复杂的压缩算法。 目前有4个版本。 论文地址源码 13.ENet详细了解ENet可参见论文：ENet: A Deep Neural Network Architecture for Real-time semantic Segmentation. ENet 是一个编码加解码的网络，将分类反向传播给原始图像进行分割。这只使用了神经网络，没有其他算法进行图像分割。 ENet被设计为在开始时尽可能使用最小数量的资源。正是因为它有着如此小的脚本，编码器和解码器网络共占有0.7MB 16fp的精度。即使这么小的型号，ENet在分割准确度上也类似于或高于其他神经网络的解决方案。 ![这里写图片描述](神经网络架构发展史/图13.png) 论文地址 14. FractalNet（参见论文： FractalNet：Ultra-Deep Neural Network without Residuals）使用递归架构，它没有在ImageNet上测试。该架构是ResNet的衍生或者更通用的ResNet。 目前有4个版本。 论文地址 15.XceptionXception是google继Inception后提出的对Inception v3的另一种改进，主要是采用depthwise separable convolution来替换原来Inception v3中的卷积操作。 目前有3个版本。 论文地址caffe实现的Xception:TensorFlow实现的Xception]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【第一部分-环境搭建】Opencv环境搭建（Visual Studio+Windows）]]></title>
    <url>%2F2018%2F12%2F05%2FOpenCV%2F%E3%80%90%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E3%80%91Opencv%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%EF%BC%88Visual%20Studio%2BWindows%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.1 库路径添加方式1.1.1 Opencv的安装及环境变量配置1.下载源码包 图1-1 将源码下载后双击可执行程序，安装在当前盘符下。 图1-2 源码地址：http://opencv.org/ 笔者使用的版本是3.0.0，最新（2017-11-6）的版本是3.3.1。安装方法都是大同小异，希望笔者不要过分在意版本，安装方法都是相通的。 2.为Opencv 添加环境变量 计算机-->属性，点击高级系统设置。 ![这里写图片描述](【第一部分-环境搭建】Opencv环境搭建（Visual Studio+Windows）/图3.png) 图1-3 出来系统属性对话框后，点击环境变量。 ![这里写图片描述](【第一部分-环境搭建】Opencv环境搭建（Visual Studio+Windows）/图4.png) 图1-4 【Tips】不管是win7还是win8或者win10，都是大同小异。 弹出如下对话框，如果没PATH，则新建PATH。 ![这里写图片描述](【第一部分-环境搭建】Opencv环境搭建（Visual Studio+Windows）/图5.png) 图1-5 【注1】最好是添加到系统变量的path路径。 笔者用的是win7，编辑系统变量中的PATH，在变量值后面输入： D:\opencv\build\x86\vc11\bin 【注2】  如果不是新建的PATH，则最前面有一个分号。如果双击后前一条路径已经自带了分号就无需加上，如果没有需要把分号也复制进去，最后要保证两段路径之间有且仅有一个分号。  变量值根据你所用的VS和Opencv的安装路径来决定，还有就是计算机的位数。不管读者使用的电脑是64位还是32位，笔者建议使用X86（32位），配置比较方便，下文都是配置的X86环境，有兴趣的可以试着配置64位的。对于版本的的选择应该是比当前是使用的低一位，笔者用的是VS12版本，所以选择了VC11下的bin目录，以此类推。 1.1.2 VS2012 的配置及测试1、新建工程：选择Win32控制台应用程序，为你的工程取个名字，点击确定 图1-6 点【下一步】 图1-7 2、弹出Win32应用程序向导，按下图选中选项后，点击【完成】。 图1-8 3、配置首先找到项目的&lt;资源管理器&gt;。方法一：在菜单栏里面点&lt;视图&gt;—&lt;其他窗口&gt;—&lt;属性管理器&gt; 图1-9 方法二：在默认的VS布局中在工程一侧有&lt;属性管理器&gt;，直接单击就行了。 图1-10 点击项目-&gt;Debug|Win32-&gt;Microsoft.Cpp.Win32.userDirectories（右键属性，或者双击）即可打开属性页面。打开属性页面后，就是一番配置了。 图1-11 首先是在【通用属性】 -&gt;【VC++目录】 -&gt;【包含目录】中添加上D: opencv\build\includeD:\opencv\build\include\opencvD: \opencv\build\include\opencv2 这三个目录。 【注】这是根据安装目录而定的。接着上步，就是在【通用属性】 -&gt;【VC++目录】 -&gt;【库目录】中，添加上D:\opencv\build\x86\vc11\lib这个路径。 &lt; 图1-12 接下来就就是链接库的配置，【通用属性】 -&gt;【链接器】-&gt;【输入】-&gt;【附加的依赖项】添加3.0.0版本的lib，带d的是debug版本，不带d的是release版本的。12opencv_world300d.lib opencv_ts300d.lib 【注意】添加如2.4.9版本（或者其他3.0以下版本）的lib（这样的lib顺序是：19个带d的debug版的lib写在前面，19个不带d的release版的lib写在后面）：12345678910111213141516171819opencv_ml249d.libopencv_calib3d249d.libopencv_contrib249d.libopencv_core249d.libopencv_features2d249d.libopencv_flann249d.libopencv_gpu249d.libopencv_highgui249d.libopencv_imgproc249d.libopencv_legacy249d.libopencv_objdetect249d.libopencv_ts249d.libopencv_video249d.libopencv_nonfree249d.libopencv_ocl249d.libopencv_photo249d.libopencv_stitching249d.libopencv_superres249d.libopencv_videostab249d.lib 12345678910111213141516171819opencv_objdetect249.libopencv_ts249.libopencv_video249.libopencv_nonfree249.libopencv_ocl249.libopencv_photo249.libopencv_stitching249.libopencv_superres249.libopencv_videostab249.libopencv_calib3d249.libopencv_contrib249.libopencv_core249.libopencv_features2d249.libopencv_flann249.libopencv_gpu249.libopencv_highgui249.libopencv_imgproc249.libopencv_legacy249.libopencv_ml249.lib 好了到这里基本就配置完了，接下来下就是测试了。 4、测试新建一个类。 图1-13 在文件中输入以下内容。123456789101112131415161718192021222324252627/**Includes*********************************************************************/#include &lt;opencv2/core/core.hpp&gt; #include &lt;opencv2/imgproc/imgproc.hpp&gt; #include &lt;opencv2/highgui/highgui.hpp&gt; #include &lt;iostream&gt; /**namespace********************************************************************/ using namespace cv; using namespace std; /** * @brief 主函数 * @param None * @retval int */int main()&#123; //载入图片 Mat img = imread(&quot;pic.jpg&quot;); // 创建一个名为 &quot;图像显示&quot;窗口 namedWindow(&quot;图像显示&quot;); // 在窗口中显示图像 imshow(&quot;图像显示&quot;, img); // 等待1000 ms后窗口自动关闭 waitKey(1000); &#125; 并在main.cpp的目录下一个文件名为pic.jpg的图片。运行程序的效果就能看到图片了。 1.2 源码安装方式在开始讲解源码安装方式之前，我们需要明白为何要这么费劲编译源码呢？起初笔者也很纳闷，编译源码既繁琐又费时，而且OpenCV官网也给我们提供了对应的win pack包，下载下来配置一下不就可以使用啦。笔者相信很多初次接触OpenCV的朋友就连使用官方的win pack都有可能没有配置成功，更不要说根据自己的电脑和需求来编译源码了。 接下来笔者就来回答为何要费劲编译源码，首先，OpenCV官网对于每个版本只提供了一到两个VS版本，很多情况下，我们不一定安装有对应的VS版本；其次，当我们开发到一定阶段，官网提供的编译库不能满足我们的需求，比如使用GPU，OpenGl，使用TBB加速等，如果读者朋友还没有听过这些名词，不要紧，你可以先尝试着在网上搜素相关名词，了解其中的用途，也可关注笔者，笔者会在其他的文章中讲解这些概念和用法。基于以上两点原因，我想大家也就明白为何哟啊编译源码了吧，接下来，就跟着笔者尝试编译源码吧。 1.2.1 CMake简介CMake，是“crossplatform make”的缩写，它是一个跨平台的安装(编译)工具,可以用简单的语句来描述所有平台的安装(编译过程)。他能够输出各种各样的makefile或者project文件,能测试编译器所支持的C++特性,类似UNIX下的automake。只是 CMake 的组态档取名为 CmakeLists.txt。Cmake 并不直接建构出最终的软件，而是产生标准的建构档（如 Unix 的 Makefile 或 Windows Visual C++ 的 projects/workspaces），然后再依一般的建构方式使用。这使得熟悉某个集成开发环境（IDE）的开发者可以用标准的方式建构他的软件，这种可以使用各平台的原生建构系统的能力是CMake 和 SCons 等其他类似系统的区别之处。 1.2.2 CMake安装首先下载Camke软件，目前（2017-11-6）最新的版本是3.10.0-rc4。下载链接：https://cmake.org/download/，进入下载页面后，可以看到Cmake的Source distributions处可以下载到Cmake软件的源码，如果对这款开源软件感兴趣，不妨看看。 图1-14 而Binary distributions处可以下载到Cmake的执行文件，我们只需要下载到其执行文件即可，选择Windows win64-x64 Installer进行下载，笔者的64位电脑，所以下载的是64位的。 图1-15 下载可执行文件后，接下来就是安装了，安装很简单，笔者就不纤细介绍了。安装完成后，接下来就是使用CMake生成OpenCV源代码工程的解决方案 1.2.3 CMake生成OpenCV源代码工程的解决方案【第一步】运行cmake-gui如果在安装时没有生成桌面快捷方式，在安装路径下寻找。运行后得到如下的窗口。 &lt; 图1-16 【第二步】指定OpenCV的安装路径如下图，点击红色方框内的“Browse Source”按钮，在弹出的对话框中指定出OpenCV安装时源代码的存储路径。以版本OpenCV 3.3.1安装在D:\下为例，则在此选择路径：D: \opencv-3.3.1。 图1-17 在该路径下有一个名为CMakeLists.txt的文件，该文件就是给CMake留下的配置文件，CMake可以根据这个配置文件，通过不同的编译器选择，来生成不同的解决方案，VisualStudio的编译器对应的就生成Visual Studio版的sln解决方案。 图1-18 【注】笔者在这里使用最新的Opencv安装包-3.3.1（注意和使用库路径安装方式进行比较，这里是下载源码）。 &lt; 图1-19 【第三步】指定解决方案的存放路径如下图，点击红色方框内的“Browse Build”按钮，在弹出的对话框中指定我们存放生成的opencv解决方案的路径。比如E:/opencv。 图1-20 【第四步】第一次Configure第一次点击Configure按钮。 弹出如下进行编译器选择的对话框： 图1-21 首先选定“Use default native compilers”，然后，我们可以发现下拉列表中提供了几十种编译器给我们选择，因为我们安装了Visual Studio，会默认为我们选择好对应版本的Visual Studio编译器，比如Visual Studio 12（即待会儿会生成对应VS2012的sln解决方案）确认无误后，单击“finish”按钮。于是，CMake开始第一次源代码配置。 【注意】在安装CMake或者OpenCV不要出现中文路径，否则可能出现不可预料的错误。看到进度条读到尽头，出现了Configuring done字样，第一次的源码配置就完成了，如图所示。 图1-22 【第五步】第二次Configure第一次配置完成之后，我们还需要进行第二次配置，于是再次点击“Configure”按钮。这次的配置是很快的，很快再次出现“Configuring done”字样，并且红色的选中部分都正常了。 【第六步】点击Generate点Generate按钮，来生成最终的解决方案了。 图1-23 看到Generating done字样，就表示大功告成，可以去之前我们指定的E:\opencv下找寻我们生成的解决方案了。 图1-24 1.2.4编译OpenCV.sln打开生成的Opencv工程，选择CMakeTargets下INSTALL，右键“生成”，生成Debug版dll，lib。切换编译模式为Release模式，重复上一步生成Release版dll，lib。（如果使用Debug就不需要编译Release版本了） 编译完成后就能看到最终Debug版和Release版（如果选择编译了）的dll，lib，以及文档目录doc，头文件目录include（bin内为两个版本dll，lib内为两个版本lib）。 编译后的目标库在E:\opencv\install文件夹下，具体路径是选择的路径决定。接下来的配置和库路径的配置方式相同，这里编译后的install文件夹就相当于win pack包的build文件夹，所以博主就不在重复了，不明白前看前文。]]></content>
      <categories>
        <category>OpenCV</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【第一部分-环境搭建】OpenCV环境搭建（Linux）]]></title>
    <url>%2F2018%2F12%2F05%2FOpenCV%2F%E3%80%90%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E3%80%91OpenCV%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%EF%BC%88Linux%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.1源码方式安装OpenCV1.1.1安装OpenCV使用OpenCV-3.1.0和Python3环境搭建步骤 步骤0： 打开终端，我们先更新和升级已安装的软件包，然后更新Raspberry Pi固件。 sudo apt-get update sudo apt-get upgrade 等待一段时间后，更新结束，如果你的Linux长时间没有更新，该部分耗时较久。 步骤1： 安装所需的工具和库，笔者在这里一个命令完成上面的很多步骤，请读者朋友注意对比。 sudo apt-get install build-essential cmake pkg-config libjasper-dev libpng12-dev libjpeg-dev libpng-dev libtiff-dev libgtk2.0-dev libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libatlas-base-dev gfortran libjasper-dev libdc1394-22-dev python-dev python-numpy 步骤2： 下载和解压OpenCV： sudo wget -O opencv-3.1.0.zip http://sourceforge.net/projects/opencvlibrary/files/opencv-unix/3.1.0/opencv-3.1.0.zip/download 【注1】直接下载可能比较慢，读者朋友可以直接到官网去下载源码，再用U盘拷贝到linux中或使用FTP等下载。 链接：https://sourceforge.net/projects/opencvlibrary/files/opencv-unix/ 【注2】最新的版本版本是3.3.1，读者朋友只需把3.1.0换成3.3.1即可，其他都是一样的。 sudo unzip opencv-3.1.0.zip cd opencv-3.1.0 安装： sudo mkdir build cd build sudo cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_NEW_PYTHON_SUPPORT=ON -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=ON -D BUILD_TBB=ON –D WITH_TBB=ON .. 编译OpenCV： sudo make 最后，我们安装OpenCV： sudo make install 更新搜索动态链接库 sudo ldconfig **1.1.2测试程序** 【C++】——通过代码载入一张图片，通过opencv把彩色图片转换为黑白图片，并把原图和转换后的图片输出到屏幕中。 1234567891011121314151617181920212223242526272829303132333435363738394041/**Includes*********************************************************************/#include &lt;opencv2/core/core.hpp&gt; #include &lt;opencv2/imgproc/imgproc.hpp&gt; #include &lt;opencv2/highgui/highgui.hpp&gt; #include &lt;iostream&gt; /**namespace********************************************************************/ using namespace cv; using namespace std; /** * @brief 主函数 * @param argc 命令行参数个数 argv 命令行参数 * @retval int */int main (int argc, char **argv) &#123; Mat image, image_gray; //读取图片 image = imread(argv[1], CV_LOAD_IMAGE_COLOR ); if (argc != 2 || !image.data) &#123; cout &lt;&lt; &quot;No image data\n&quot;; return -1; &#125; cvtColor(image, image_gray, CV_RGB2GRAY); //创建显示窗口 namedWindow(&quot;image&quot;,CV_WINDOW_AUTOSIZE); namedWindow(&quot;image gray&quot;,CV_WINDOW_AUTOSIZE); //显示图片 imshow(&quot;image&quot;, image); imshow(&quot;image gray&quot;, image_gray); waitKey(0); return 0; &#125; 【makefile】 12345678910111213141516INCLUDE = $(shell pkg-config --cflags opencv) LIBS = $(shell pkg-config --libs opencv) SOURCES = test.cpp # 目标文件 OBJECTS = $(SOURCES:.cpp=.o) # 可执行文件 TARGET = test $(TARGET):$(OBJECTS) g++ -o $(TARGET) $(OBJECTS) -I $(INCLUDE) $(LIBS) $(OBJECTS):$(SOURCES) g++ -c $(SOURCES) clean: rm $(OBJECTS) $(TARGET) # 编译规则 $@代表目标文件 $&lt; 代表第一个依赖文件 %.o:%.cpp g++ -I $(INCLUDE) -o $@ -c $&lt; 【简要说明】 通过pkg-config --cflags opencv 获得opencv相关头文件路径，通过pkg-config --libs opencv获得opencv扩展库 【编译并执行】 make ./test raspberry.jpg 示例中载入一张名为raspberry.jpg图片。在该示例中，图片和可执行文件test应在同一个目录中。 ## 1.2 apt方式安装OpenCV **1.2.1安装OpenCV** 读者也许认为前文的方法比较麻烦，很不容易安装成功，接下来笔者将介绍如何在树莓派中通过apt方式安装OpenCV。相比于源代码方式安装OpenCV，通过apt方式安装过程步骤简单些，消耗的时间也少一些。通过apt方式安装没有自动生成opencv.pc文件，所以在编写makefile文件时不能直接使用pkg-config工具，而需要逐个指定opencv_core、opencv_imgproc等动态链接库。这也是它的劣势所在。 开始之前进行必要的更新工作。 sudo apt-get update 安装源码库。 sudo apt-get install libcv-dev 安装过程比较缓慢，请耐心等待。安装结束后，可以在/usr/include目录下opencv和opencv2下查看opencv相关的头文件(.h)，这个是树莓派中默认头文件路径。 ![这里写图片描述](【第一部分-环境搭建】OpenCV环境搭建（Linux）/图1.png) 图1-1 opencv的相关动态链接库包括： 【opencv_calib3d】——相机校准和三维重建 【opencv_core】——核心模块，绘图和其他辅助功能 【opencv_features2d】——二维特征检测 【opencv_flann】——快速最邻近搜索 【opencv_highgui】——GUI用户界面 【opencv_imgproc】——图像处理 【opencv_legacy】——废弃部分 【opencv_ml】——机器学习模块 【opencv_objdetect】——目标检测模块 【opencv_ocl】——运用OpenCL加速的计算机视觉组件模块 【opencv_video】——视频分析组件 1.2.2测试程序 【参考附件/apt-get方式】 【C++】——通过代码载入一张图片，通过opencv把彩色图片转换为黑白图片，并把原图和转换后的图片输出到屏幕中。12345678910111213141516171819202122232425262728293031323334353637383940/**Includes*********************************************************************/#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;iostream&gt;/**namespace********************************************************************/using namespace cv;using namespace std;/** * @brief 主函数 * @param argc 命令行参数个数 argv 命令行参数 * @retval int */int main(int argc,char **argv)&#123; Mat image ,image_gray; //读取图片 image = imread(argv[1],CV_LOAD_IMAGE_COLOR); if(argc != 2 || !image.data) &#123; cout &lt;&lt;&quot;No image data\n&quot;; return -1; &#125; cvtColor(image,image_gray,CV_RGB2GRAY); //创建显示窗口 namedWindow(&quot;image&quot;,CV_WINDOW_AUTOSIZE); namedWindow(&quot;image gray&quot;,CV_WINDOW_AUTOSIZE); //显示图片 imshow(&quot;image&quot;, image); imshow(&quot;image gray&quot;, image_gray); waitKey(0); return 0; &#125; 【makefile】1234567891011121314151617CC = g++ # 可执行文件 TARGET = test # C文件 SRCS = test.cpp # 目标文件 OBJS = $(SRCS:.cpp=.o) # 库文件 DLIBS = -lopencv_core -lopencv_imgproc -lopencv_highgui # 链接为可执行文件 $(TARGET):$(OBJS) $(CC) -o $@ $^ $(DLIBS) clean: rm -rf $(TARGET) $(OBJS) # 编译规则 $@代表目标文件 $&lt; 代表第一个依赖文件 %.o:%.cpp $(CC) -o $@ -c $&lt; 【简单说明】DLIBS = -lopencv_core -lopencv_imgproc -lopencv_highgui示例中使用了opencv中的核心部分、图像处理部分和GUI部分，所以依次增加opencv_core、opencv_imgproc、opencv_highgui动态链接库。该部分和和【树莓派学习笔记——源代码方式安装opencv】中的示例稍有不同，前文中的makefile使用LIBS = $(shell pkg-config —libs opencv)引入所有的opencv动态链接库，此处手动指定相关库按需链接。【编译】 make 【执行】 ./test image.jpg 可执行文件test和image.jpg应在同一个目录中。 1.3 OpenCV 整体结构上文讲解了OpenCV的安装，也相应给出了简单的例子。在具体学习OpenCV的具体功能块之前，我们先来看看OpenCV源码的整体框架，这样也能方便我们在后面的学习中获得更加清晰的思路。 1.3.1文件结构要了解整体框架，切入点在于opencv/build目录下的include文件夹，因为这下面包含了OpenCV源码所有的头文件。include下面有两个文件夹：opencv和opencv2： 图1-2 不难看出，opencv中存放的是旧版中保留的部分OpenCV的头文件，而opencv2中包含的则是改版之后的OpenCV2的各种头文件。 1.opencv文件目录： 图1-3 1.opencv2文件目录： 图1-4 在这个文件夹下面，我们可以看到很多子文件目录，这些目录都是按照功能模块进行头文件整合，相同功能块的放在同一子目录下面，其中opencv_modules.hpp这个头文件中，定义了opencv2中所有模块的宏： 图1-5 1.3.2功能模块 上面的介绍中我们介绍文件结构的同时，其实也说到了opencv2中的每个子文件夹就对应一个功能模块，那么我们接下来就看看每个功能模块的具体作用，标红为最常用的库文件： 1、【calib3d】——其实就是就是Calibration（校准）加3D这两个词的组合缩写。这个模块主要是相机校准和三维重建相关的内容。基本的多视角几何算法，单个立体摄像头标定，物体姿态估计，立体相似性算法，3D信息的重建等等。 2、【core】——核心功能模块，包含如下内容：  OpenCV基本数据结构  动态数据结构  绘图函数  数组操作相关函数  辅助功能与系统函数和宏  与OpenGL的互操作 3、【imgproc】——Image和Processing这两个单词的缩写组合。图像处理模块，这个模块包含了如下内容：  线性和非线性的图像滤波  图像的几何变换  其它（Miscellaneous）图像转换  直方图相关  结构分析和形状描述  运动分析和对象跟踪  特征检测  目标检测等内容 4、【features2d】 ——也就是Features2D， 2D功能框架 ，包含如下内容：  特征检测和描述  特征检测器（Feature Detectors）通用接口  描述符提取器（Descriptor Extractors）通用接口  描述符匹配器（Descriptor Matchers）通用接口  通用描述符（Generic Descriptor）匹配器通用接口  关键点绘制函数和匹配功能绘制函数 5、【flann】—— Fast Library for Approximate Nearest Neighbors，高维的近似近邻快速搜索算法库，包含两个部分：  快速近似最近邻搜索  聚类 6、【gpu】——运用GPU加速的计算机视觉模块 7、【highgui】——也就是high gui，高层GUI图形用户界面，包含媒体的I / O输入输出，视频捕捉、图像和视频的编码解码、图形交互界面的接口等内容 8、【ml】——Machine Learning，机器学习模块， 基本上是统计模型和分类算法，包含如下内容：  统计模型 （Statistical Models）  一般贝叶斯分类器 （Normal Bayes Classifier）  K-近邻 （K-NearestNeighbors）  支持向量机 （Support Vector Machines）  决策树 （Decision Trees）  提升（Boosting）  梯度提高树（Gradient Boosted Trees）  随机树 （Random Trees）  超随机树 （Extremely randomized trees）  期望最大化 （Expectation Maximization）  神经网络 （Neural Networks）  MLData 9、【objdetect】——目标检测模块，包含Cascade Classification（级联分类）和Latent SVM这两个部分。10、【photo】——也就是Computational Photography，包含图像修复和图像去噪两部分11、【stitching】——images stitching，图像拼接模块，包含如下部分：  拼接流水线  特点寻找和匹配图像  估计旋转  自动校准  图片歪斜  接缝估测  曝光补偿  图片混合 12、【superres】——SuperResolution，超分辨率技术的相关功能模块13、【ts】——opencv测试相关代码，不用去管他14、【video】——视频分析组件，该模块包括运动估计，背景分离，对象跟踪等视频处理相关内容。15、【Videostab】——Video stabilization，视频稳定相关的组件，官方文档中没有多作介绍，不管它了。 以上就是OpenCV的大体模块，笔者在这里列出的是3.1.0和3.0.0共同所拥有的，总之大体相同，要想深入研究的读者请自行对比吧。看到这里，相信大家已经对OpenCV的模块架构设计有了一定的认识。另外OpenCV的参考例程也是这样分块的。 【注】笔者树莓派（Linux操作系统）用的3.1.0，PC端用的是3.0.0，经过笔者比较，二者区别不大，在后文中有区别的地方笔者会特别指出。]]></content>
      <categories>
        <category>OpenCV</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《WEB开发-HEXO博客搭建》第5章 Hexo图片显示问题]]></title>
    <url>%2F2018%2F12%2F05%2FHexo%2F%E7%AC%AC5%E7%AB%A0%20Hexo%E5%9B%BE%E7%89%87%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[笔者在使用Hexo搭建个人博客的过程中，发现使用链接（! [这里输入图片描述] (xxxx/图片名.jpg)）的方式引用图片，无法显示，如下图所示。笔者都差点放弃了使用github搭建个人博客。笔者最近找到了解决方案，于是记录下来，希望对朋友们有用。 ![这里写图片描述](第5章 Hexo图片显示问题/图0.png) 1.设置站点配置_config.ymlpost_asset_folder: true 2.安装插件 npm install https://github.com/CodeFalling/hexo-asset-image --save 或 npm install hexo-asset-image --save ![这里写图片描述](第5章 Hexo图片显示问题/图2.png) 来源：https://github.com/CodeFalling/hexo-asset-image **3.引用图片 ** 运行hexo n "xxxx"来生成md博文时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹。接下来就是利用makdown。 在xxxx.md中想引入图片时，先把图片复制到xxxx这个文件夹中，然后只需要在xxxx.md中按照markdown的格式引入图片： ! [ 这里输入图片描述] ( xxxx/图片名.jpg ) hexo g生成页面后，进入public文件中查看相关字段，可以发现，html标签内的语句是&lt; img src=”…xxxx/图片名.jpg”&gt;，而不是&lt; img src=”xxxx/图片名.jpg&gt;。这很重要，关乎你的网页是否可以真正加载你想插入的图片。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《WEB开发-HEXO博客搭建》第4章 同步到Coding]]></title>
    <url>%2F2018%2F12%2F05%2FHexo%2F%E7%AC%AC4%E7%AB%A0%20%E5%90%8C%E6%AD%A5%E5%88%B0Coding%2F</url>
    <content type="text"><![CDATA[1.注册Coding.net账号Coding官网：https://coding.net/【注意】如果不想花钱的话要绑定腾讯云可以免费升级，笔者使用的是绑定腾讯云升级的。 图1 2.新建项目注意项目名与注册用的账户名一致，这里我用的是ouxiaolong。 图2 图3 3.添加公钥上面设置完毕之后点击创建项目，然后点击设置-&gt;部署公钥-&gt;新建部署公钥，之前部署到Github上的时候，本地目录 C\User(中文为用户)(电脑用户名).ssh 目录下会有 id_rsa.pub 公钥文件，打开然后复制里面的内容，直接贴在这里的公钥框中。 图4 图5 记得要勾选【授予推送权限】,否则在后面运行hexo d时会提示错误：Coding.net Tips : [Deploy key is not allowed to push!]fatal: Could not read from remote repository.原因就是没有推送权限。打开Git命令窗口Git shell，输入一下指令：ssh -T git@git.coding.NET假如出现以下输出结果，表示公钥绑定成功。 4.修改hexo配置打开hexo本地的配置文件 _config.yml，修改 deploy 的配置内容，这里设置了运行hexo d之后部署的目的地址，原本只有Github地址，现在添加多Coding.net的地址，其中BruceOu是注册该平台的用户名。 在source目录下新建一个文件，命名为Statifile，不带文件后缀。 5.正式部署到Coding.net打开命令行窗口，定位到当前hexo项目的根目录下，运行以下指令将本地博客部署到Github和Coding.net上：hexo ghexo d 6.设置Coding Page打开Coding.net的项目管理界面，打开代码-&gt;Pages服务，选择部署来源为master分支，然后保存即可。 图6 图7 7.测试效果打开bruceou.coding.me访问我们的博客，刚配置完访问的时候出现404错误很正常，需要等待10分钟左右才能生效。 图8]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《WEB开发-HEXO博客搭建》第3章 Hexo博客域名添加]]></title>
    <url>%2F2018%2F12%2F05%2FHexo%2F%E7%AC%AC3%E7%AB%A0%20Hexo%E5%8D%9A%E5%AE%A2%E5%9F%9F%E5%90%8D%E6%B7%BB%E5%8A%A0%2F</url>
    <content type="text"><![CDATA[CSDN博客地址B站配套视频 Hexo官方：https://hexo.io/Hexo官方(中文)：https://hexo.io/zh-cn/ 前文笔者使用Hexo和GitHub搭建个人博客空间，使用markdown写博客既方便，展示出来的样式也还算满意，GitHub的域名有点长，还有就是访问速度比较慢，今天就试着把访问域名替换成自己的域名。废话不说，开干吧。 1.申请个人域名首先得先拥有一个自己的域名，我用的是阿里云里买的一个以.cn为后缀的域名时送了一个.top结尾的域名，笔者已经使用了.cn结尾的域名，笔者买的期限是3年，也就一百一块，愿意花这个钱就继续往下看吧。关于阿里云建站请看这篇文章：https://blog.csdn.net/u013162035/article/details/80722347 2.域名添加 DNS 解析github官网提供的主机ip地址：192.30.253.113。域名查询：http://site.ip138.com/但是我们要绑定自己的域名，就需要绑定自己的IP，可以通以下命令查看： $ping 你的用户名.github.io 将这个作为主机地址，给域名的DNS解析添加记录。登录阿里云，到域名列表，选择要绑定的域名。 图1域名选择 接下来，就是在【域名解析】中点击【添加记录】，添加两条记录，添加一个 A记录，然后再添加一个 CNAME记录主机地址填的是我们原本用来访问github博客的地址： githubname.github.io。 图2域名解析添加记录 3.创建 CNAME 文件在hexo本地目录 source 目录下面新建一个文件，取名为 CNAME (无后缀)，内容就是上面所说到的自己的域名如下： 图3 运行hexo指令使配置修改起效： $hexo g //会在public中生成一个CNAME文件$hexo d //修改内容提交到github博客上 4.测试假如设置成功，此时在浏览器中输入我们的域名可以看到网页啦。 图4]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《WEB开发-HEXO博客搭建》第2章 Hexo博客配置]]></title>
    <url>%2F2018%2F12%2F05%2FHexo%2F%E7%AC%AC2%E7%AB%A0%20Hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[CSDN博客地址B站配套视频 Hexo官方Hexo官方(中文)Hexo主题Next 主题 图1 2.1 Hexo页面添加及设置默认有些页面是没有的，需要手动添加，进入博客文件夹，打开Git bash。123$hexo new page &quot;categories&quot;$hexo new page &quot;tags&quot; $hexo new page &quot;about&quot; 编辑 tags/index.md 和categories/index.md和about/index.md分别添加如下内容：12type: &quot;categories&quot;layout: &quot;categories&quot; 12type: &quot;tags&quot;layout: &quot;tags&quot; 12type: &quot;about&quot;layout: &quot;about&quot; 主题的 _config.yml 文件中的 menu 中进行匹配。123456menu: Home: / //主页 Archives: /archives //分类 categories: /categories //归档 tags: /tags //标签 about: /about //关于 2.2添加评论功能来必力官网： https://livere.com没有账号的注册账号，打开来必力官网： https://livere.com，点击上方的安装，选择免费的city版本。 图2 图3 点击【申请获得代码】，进入下一步操作。复制其中的uid字段。 123456789101112131415161718&lt;!-- 来必力City版安装代码 --&gt;&lt;div id=&quot;lv-container&quot; data-id=&quot;city&quot; data-uid=&quot;MTAyMC8zNzMzMC8xMzg2NA==&quot;&gt; &lt;script type=&quot;text/javascript&quot;&gt; (function(d, s) &#123; var j, e = d.getElementsByTagName(s)[0]; if (typeof LivereTower === &apos;function&apos;) &#123; return; &#125; j = d.createElement(s); j.src = &apos;https://cdn-city.livere.com/js/embed.dist.js&apos;; j.async = true; e.parentNode.insertBefore(j, e); &#125;)(document, &apos;script&apos;); &lt;/script&gt;&lt;noscript&gt; 为正常使用来必力评论功能请激活JavaScript&lt;/noscript&gt;&lt;/div&gt;&lt;!-- City版安装代码已完成 --&gt; 图4 打开主题目录下的 blog/themes/某个主题/_config.yml 配置文件，定位到 livere_uid 字段，粘贴上刚刚复制的UID。 至此，大功告成。效果展示测试评论如图所示： 图5 2.3统计配置笔者使用的是不蒜子统计注意：此特性在版本 5.0.1 中引入，要使用此功能请确保所使用的 NexT 版本在此之后。 全局设置 编辑主题配置文件中的busuanzi_count的配置项。当enable: true时，代表开启全局开关。若site_uv、site_pv、page_pv的值均为false时，不蒜子仅作记录而不会在页面上显示。  站点UV设置当site_uv: true时，代表在页面底部显示站点的UV值。site_uv_header和site_uv_footer为自定义样式配置，相关的值留空时将不显示，可以使用（带特效的）font-awesome。显示效果为[site_uv_header]UV值[site_uv_footer]。 //效果：本站访客数12345人次site_uv: truesite_uv_header: 本站访客数site_uv_footer: 人次  站点PV设置当site_pv: true时，代表在页面底部显示站点的PV值。site_pv_header和site_pv_footer为自定义样式配置，相关的值留空时将不显示，可以使用（带特效的）font-awesome。显示效果为[site_pv_header]PV值[site_pv_footer]。 //效果：本站总访问量12345次site_pv: truesite_pv_header: 本站总访问量site_pv_footer: 次  单页面PV配置当page_pv: true时，代表在文章页面的标题下显示该页面的PV值（阅读数）。page_pv_header和page_pv_footer为自定义样式配置，相关的值留空时将不显示，可以使用（带特效的）font-awesome。显示效果为[page_pv_header]PV值[page_pv_footer]。 //效果：本文总阅读量12345次page_pv: truepage_pv_header: 本文总阅读量page_pv_footer: 次 2.4搜索配置笔者使用的是Local Search，添加百度/谷歌/本地 自定义站点内容搜索。一、安装 hexo-generator-searchdb在站点的根目录下执行以下命令： $ npm install hexo-generator-searchdb —save 二、编辑站点配置文件，新增以下内容到任意位置12345search: path: search.xml field: post format: html limit: 10000 三、编辑主题配置文件，启用本地搜索功能 123# Local searchlocal_search: enable: true]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《WEB开发-HEXO博客搭建》第1章 Hexo博客搭建]]></title>
    <url>%2F2018%2F12%2F05%2FHexo%2F%E7%AC%AC1%E7%AB%A0%20Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[CSDN博客地址B站配套视频 Hexo官方：https://hexo.io/Hexo官方(中文)：https://hexo.io/zh-cn/Node.js官方网站：https://nodejs.org/en/Node.js官方文档：https://nodejs.org/en/docs/Node.js安装文档：https://nodejs.org/en/download/package-manager/ 1.1 Hexo简介Hexo是一个快速, 简洁且高效的博客框架. 让上百个页面在几秒内瞬间完成渲染. Hexo支持Github Flavored Markdown的所有功能, 甚至可以整合Octopress的大多数插件. 并自己也拥有强大的插件系统。 1.2 node.js安装Hexo是基于node.js的，所以我们在安装它之前需要用到npm安装工具，这个工具是 node.js 安装包的工具，所以，我们先要安装 node.js。笔者是用的Windows 64位的，到node.js下载安装包。 图1 下载后直接安装就可以啦，和普通的软件没有什么大的区别，所有笔者就不赘述了。 1.3 GitHub账户创建及客户端安装关于git账户创建及客户端下载安装等可参看笔者的博客，笔者在这里就不在赘述了。GitHub官网：https://github.com/Git和Github的使用：https://blog.csdn.net/u013162035/article/details/78476880Git下载：https://git-scm.com/downloadsGit安装：https://blog.csdn.net/u013162035/article/details/78464161 在github网页上创建一个以username.github.io命名的repositories,此时username为自己github的账号名称。 1.4安装hexo使用npm安装Hexo，输入以下命令： $ npm install hexo-cli -g 1.5创建Blog笔者在D盘下新建一个blog的文件夹，然后进入blog文件夹，单击右键打开git bash。1. 创建一个叫blog网站$ hexo init 如果没有进入blog文件夹， 就会在当前目录进行初始化。这是初始化命令就要加blog。$ hexo init blog 如果后面跟了名子就会创建目录并在目录进行初始化操作, 以这个名子为目录名。2. 我们进入创建的blog目录里. 并运行该服务$ npm install $ hexo server 【注】hexo命令$ hexo install 3. 测试网页打开浏览器, 在地址栏输入http://localhost:4000/可以看到我们刚刚创建的blog首页 4.修改blog目录下的_config.yml配置文件将网站自部署到Github上$ vim _config.yml 添加如下内容 123git repo: git@github.com:用户名/用户名.github.io.gitbranch: master 【注】在type前面需要增加两个空格，在type的冒号后面需要增加一个空格。请保持代码风格一致，否则会出现错误或是不正确的问题。5.安装部署使用到的git插件在这里我们使用的是git源码管理工具，所以，我需要安装git包进行部署，安装这个插件才能使用git进行自动部署。 $ npm install hexo-deployer-git -save 在接下来，我们将要生成网站了，首先清理一下缓存。$hexo clean 6.进行生成网站当我们部署网站前，需要先生成静态网站。它会自动在目录下创建public的目录, 并将新生成的网页存放在这个目录里。 $ hexo g或hexo generate 7.进行自动部署网站注意部署前需要重新生成网站, 每一次修改后都需要重新生成网站并进行部署，生成网站前第6步。 $ hexo d或hexo deploy 如果在部署出现错误信息如果下: 请参考第5步，需要安装git插件ERROR Deployer not found: git以上两步可以使用一步就可以搞定： $hexo g -d 【注】上述的部署指令中hexo deploy可以换成hexo server，两者的区别在于，前者是将博客部署到远程的Github上，而后者是运行在本地，通过http://localhost:4000在浏览器中访问。后者是为了调试配置方便而使用，但是最终本地博客还是需要hexo deploy指令将其部署至Github上。接下来就是查看是否成功啦。打开浏览器输入IP地址。 图2 表明创建成功了。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Git与Github使用笔记》第9章 GitHub创建静态页面]]></title>
    <url>%2F2018%2F12%2F05%2FGit%2F%E7%AC%AC9%E7%AB%A0%20GitHub%E5%88%9B%E5%BB%BA%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[GitHub Pages可以被认为是用户编写的、托管在github上的静态网页。废话就不说了，关于GitHub Pages的相关内容自己上网查看吧， 博主在这里教大家快速搭建个人主页。GitHub Pages首页 第一步：创建Github库参见博主的《Git和GitHub是用笔记》的第7章《Git和Github的使用》的第1节，把文件名改为“用户名.github.io”，其他相同。 【注】如过没有配置KEY，就参看博主的《Git和GitHub使用笔记》的第7章《Git和Github的使用》的第2节内容。 第二步：克隆存储库转到你想要存储项目的文件夹，本地电脑上（博主使用的Windows系统），并克隆新的存储库: 第三步：新建网页代码 输入项目文件夹并添加索引。html文件: 【注】博主在这里只是告诉大家创建的流程，这里可是将你创建好的整个网站工程放到该目录下，在推送到GitHub就可以了。 第四步：推送到GitHubAdd, commit, and push : 【注】问题： 解决： 第五步：验证网页是否创建成功https://username.github.io.【注】username是你创建的用户名，笔者创建成功后，进入的界面如下图所示。 附上博主的个人网站 https://ouxiaolong.github.io./]]></content>
      <categories>
        <category>git&amp;GitHub</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Git与Github使用笔记》第8章 github常见操作和常见错误]]></title>
    <url>%2F2018%2F12%2F05%2FGit%2F%E7%AC%AC8%E7%AB%A0%20github%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C%E5%92%8C%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[1.如果输入$ ssh -T git@github.com出现错误提示：Permission denied (publickey).因为新生成的key不能加入ssh就会导致连接不上github。 解决办法如下： 先输入$ ssh-agent，再输入$ ssh-add ~/.ssh/id_key，这样就可以了。 如果还是不行的话，输入ssh-add ~/.ssh/id_key 命令后出现报错Could not open a connection to your authentication agent.解决方法是key用Git Gui的ssh工具生成，这样生成的时候key就直接保存在ssh中了，不需要再ssh-add命令加入了，其它的user，token等配置都用命令行来做。 最好检查一下在你复制id_rsa.pub文件的内容时有没有产生多余的空格或空行，有些编辑器会帮你添加这些的。 2.如果输入$ git push origin master提示出错信息：error:failed to push som refs to ……. 解决办法如下： 先输入$ git pull origin master //先把远程服务器github上面的文件拉下来 再输入$ git push origin master 如果出现报错 fatal: Couldn’t find remote ref master或者fatal: ‘origin’ does not appear to be a git repository以及fatal: Could not read from remote repository. 则需要重新输入$ git remote add origingit@github.com:djqiang/gitdemo.git 3.用git在本地创建一个项目的过程12345678$ makdir ~/hello-world //创建一个项目hello-world$ cd ~/hello-world //打开这个项目$ git init //初始化 $ touch README$ git add README //更新README文件$ git commit -m &apos;first commit&apos; //提交更新，并注释信息“first commit”$ git remote add origin git@github.com:defnngj/hello-world.git //连接远程github项目 $ git push -u origin master //将本地项目更新到github项目上去 4. gitconfig配置文件Git有一个工具被称为git config，它允许你获得和设置配置变量；这些变量可以控制Git的外观和操作的各个方面。这些变量可以被存储在三个不同的位置： /etc/gitconfig 文件：包含了适用于系统所有用户和所有库的值。如果你传递参数选项’—system’ 给 git config，它将明确的读和写这个文件。  ~/.gitconfig 文件 ：具体到你的用户。你可以通过传递—global 选项使Git 读或写这个特定的文件。 位于git目录的config文件 (也就是 .git/config) ：无论你当前在用的库是什么，特定指向该单一的库。每个级别重写前一个级别的值。因此，在.git/config中的值覆盖了在/etc/gitconfig中的同一个值。 在Windows系统中，Git在$HOME目录中查找.gitconfig文件（对大多数人来说，位于C:\Documents and Settings\$USER下）。它也会查找/etc/gitconfig，尽管它是相对于Msys 根目录的。这可能是你在Windows中运行安装程序时决定安装Git的任何地方。]]></content>
      <categories>
        <category>git&amp;GitHub</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Git与Github使用笔记》第7章 Git和Github的使用]]></title>
    <url>%2F2018%2F12%2F05%2FGit%2F%E7%AC%AC7%E7%AB%A0%20Git%E5%92%8CGithub%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[7.1Github库的创建登录成功后界面，没有账户的先注册一个账户。首先要创建仓库，要想使用github来托管自己的项目代码，因此先要创建一个仓库，仓库分公开的和私有的，公开的是免费的，私有的是收费的，我使用的是公开的仓库，如下创建方式 图1 点击New repository按钮，如果是首次使用会要求确认邮箱，确认后。弹出如下界面，第一行填仓库名，这里就随便叫Test了，第二行是对这个仓库的描述，之后那个Public就是公共仓库的意思，接下来的README就是在仓库里创建一个README文件，可以往里写一些介绍你这个项目的功能之类的东西，再下面那个Add gitignore按钮，可以选择你这个项目是用什么语言之类的,我这里选择了，后面那个License我没有选，点击”Create repository”。 图2创建库 创建仓库成功后,界面如下显示,可以点击README.md来编译这个文件。 图3 图4 7.2配置7.2.1 Git配置1.Git bash打开之后输入命令如下：ssh-keygen -t rsa -C “邮箱地址”【注意】ssh-keygen之间是没有空格的,其他的之间是有空格的。GitHub邮箱：该命令后面的邮箱就是你的注册邮箱。路径选择：使用该命令之后, 会出现提示选择ssh-key生成路径, 这里直接点回车默认即可, 生成的ssh-key在默认路径中。密码确认：这里我们不使用密码进行登录, 用密码太麻烦，直接回车。当然，如果你想使用密码登录，那就输入密码（密码他不能太短）之后回车。操作显示截图如下： 图5 2.在上面显示的默认路径下找到生成的Key，我的默认路径是“C:\Users\ouxiaolong.ssh”，如果不知道自己的默认路径，可以输入“pwd”命令查看。3.使用记事本或者UE工具打开“id_rsa.pub”文件, 将该文件中的内容复制到GIT服务器上。进入GitHub网站：登录GitHub, 选择“Settings”，操作截图显示如下： 图6 左侧选择“SSH and GPG keys”，操作截图显示如下： 图7 4.点击右侧的“New SSH key”，在显示的输入框中将前面生成的key输入进去，操作截图如下： 图8 输入之后点击“Add SSH key”5.点击添加之后，显示截图如下： 图9 同时，我们配置的邮箱也会收到相应的邮件，截图如下： 图10 这样，我们本地的key就添加到GitHub上了。当然，如果你对应的Git服务器是你们公司或者你自己搭建的，那只需要登录相应的Git服务器，然后将你本地生成的key添加上去即可。6.验证是否配置成功输入命令：ssh -T git@github.com验证时可能让你输入YES。成功提示 : 如果出现“Hi ouxiaolong! You’ve successfully authenticated, but GitHub does not provide shell access.”就说明配置成功，可以连接上GitHub，操作截图显示如下： 图11 7.配置本地用户和邮箱我们需要设置一个用户名和邮箱，这是用来上传本地仓库到GitHub时，在GitHub中显示代码上传者的。配置命令如下：git config —global user.name “xxx” //设置用户名git config —global user.email “邮箱” //设置邮箱操作截图显示如下：到这里，我们的Git客户端就配置完成了，并且我们本地的key也成功上传到Git服务端了。 图12 7.2.2使用Git + Github到现在为止，我们就算把Github配置完了，Git的相关操作不懂参看前几章，这里就不在赘述了。现在就来托管我们的项目吧，刚才我们已经在github上面创建了一个叫Smart_Home的仓库，那么我们现在就在本地创建一个目录，来管理这个仓库。  随意创建了一个目录叫Git 图13  右击目录，出现的菜单中有Git Bash Here，点击它。 图14  这时候就在这个目录上打开了我们的终端。 图15  这时候输入 git init，来完成初始化工作。命令：git init//初始化 图16 命令：git remote add origin git@github.com:Ouxiaolong/Smart_Home.git 图17 命令：git pull git@github.com: Ouxiaolong/Smart_Home.git 图18  上传本地文件到仓库首先执行增加命令，如下：命令：git add . 图19 add后面加了一个点，是想要提交所有文件，如果想提交指定的文件，可以写文件名，执行完增加命令后，要执行提交命令，如下：命令：git commit –m “版本号（自定义）” 图20 -m后面跟提示信息，这个提示信息是一定要写的，不仅是规则，同时也方便我们记录我们提交的过程，写清晰为什么提交或修改了什么是非常有用的，提交完成后，我们就要把它推送到远程仓库上去了，命令如下：命令：git push git@github.com: Ouxiaolong/Smart_Home.git 图21 再到github上看到如下显示表示添加成功。 图22 这样就完成了我们要做的所有任务。]]></content>
      <categories>
        <category>git&amp;GitHub</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Git与Github使用笔记》第6章 copssh]]></title>
    <url>%2F2018%2F12%2F05%2FGit%2F%E7%AC%AC6%E7%AB%A0%20copssh%2F</url>
    <content type="text"><![CDATA[6.1 Copssh的安装下载地址：https://www.itefix.net/copssh 图1 点击next。 图2 点击I Agree。 图3 其中：安装目录根据实际自己选择，避免路径中有空格，造成不必要的麻。再点击next。设置SSH的帐号密码，再单击Install。 图4 图5 表示安装成功。 6.2 Copssh的配置选择COPSSH Control Panel-&gt;Users-&gt;Add 图6 点击Forward继续。 图7 选择用户，点击Forward继续。 图8 默认选择，点击Forward继续。 图9 点击Apply继续。 图10 再回到COPSSH Control Panel-&gt;Users，选择用户并应用此用户。 图11 表示用户添加成功。再COPSSH Control Panel-&gt;Stauts下开启服务。 图12 如上图启动应用。在启动应用的情况下，打开cmd，登陆ssh。（登陆方法很多） 图13 【注意】命令行是Windows自带的命令行，另外环境变量应根据实际情况设置。要让COPSSH支持git命令，应在D:\Git\Git\mingw64\libexec\git-core目录下，找到以下文件。复制到D:\Git\Copssh\ICW\bin目录下。 图14 将D:\Git\Git\mingw64\bin目录下的libiconv-2.dll复制到D:\Git\Copssh\ICW\bin目录下。 6.3建库操作 链接Git版本库登录完成后，此时的实际路径是在D:\Git\Copssh\ICW\Repository建库。打开Bash，输入代码：命令：ssh-keygen –t rsa –C “you@example.com” //输入邮箱生成公钥，默认名称为id_rsa（如果我们没有生成key的话，直接用电脑命令行可能连接不成功。如果用命令行可以连接的话，同样可以用命令行来生成。）然后一直回车，如图显示便设置成功（如果该路径已经有了该文件，会提醒你是否覆盖，输入y确认就行）。 图15 根据文件路径找到id_rsa.pub和id_rsa文件，笔者的在D:\Git\Copssh\ICW\home\ouxiaolong.ssh目录下。在当前文件夹中，新建文件authorized_keys（无后缀），用记事本打开，把id_rsa.pub内容复制进去保存。打开COPSSH选定用户，点击“keys•••” 图16 如果public key中有内容说明key添加成功。 图17 打开电脑命令行，进入SSH安装目录下的bin文件夹，调用ssh.exe文件，输入以下代码：“ssh 用户名@你的服务器名称或者IP地址”，我这里输入的是IP地址。回车 ，输入yes。 图18 出现上图所示表示链接成功。登录完成后，此时的实际路径是在D:\Git\Copssh\ICW  建库操作建库操作步骤如下：mkdir git//创建git文件夹cd git//进入git文件夹git init //版本库初始化，会以git为库名建立一个新库建好仓库后打开git进入隐藏文件夹.git，用记事本打开config文件加入[receive]denyCurrentBranch = ignore服务端所有工作完成！ 【小贴士】建库时错误处理：在建库时输入git init后出现下图情况： 图19 为了解决方法， 找到D:\Git\Copssh\ICW\home\ouxiaolong.bashrc和D:\Git\Copssh\ICW\etc\profile打开这两个文件。在最后加上这段：itpath=’cygdrive/D/Git/Git/mingw64/bin’gitcorepath=’cygdrive/D/Git/Git/mingw64/libexec/git-core’PATH=${gitpath}:${gitcorepath}:${PATH}修改好后，Dos（cmd命令符窗口）需要重新开启。重新写git init，git clone；都不会出错了。]]></content>
      <categories>
        <category>git&amp;GitHub</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Git与Github使用笔记》第5章 安装eclipse的插件EGit以及使用]]></title>
    <url>%2F2018%2F12%2F05%2FGit%2F%E7%AC%AC5%E7%AB%A0%20%E5%AE%89%E8%A3%85eclipse%E7%9A%84%E6%8F%92%E4%BB%B6EGit%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[5.1 安装eclipse的EGit的插件下载地址：http://www.eclipse.org/egit/download/ 第一步：打开eclipse- >help-.Install New Software 图 1 图2 第二步：点击Add，找到安装包的位置。 图3 第三步：按下图所示勾选。 图4 第四步：再单击Next，进入下一步，同意声明后，点击Finish即可。 图5 第五步：重启eclipse后。查看是否安装成功。在eclipse->Window->Preferences，显示有Git表示安装成功。 图6 5.2 eclipse中Git的使用第一步：单击eclipse- >Open Perspespective，选择Git，单击OK即可。 图7 第二步：克隆文件 图8 图9 点击next，直到出现下图所示，按一下操作。 图10 这样就克隆了文件。 第三步：导入项目单击鼠标右键-&gt;Import projects 图11 图12 图13 图14 现在就开始编码了。 第四步：建立用户信息、在正式编码之前，应该建立用户信息。在eclipse-&gt;Window-&gt;Preferences-&gt;Add Entry… 图15 填写用户名了邮箱。 图16 图17 填写完后如下所示表成功。 图18 图19 第五步：修改并同步文件修改后文件后，选择文件右击-&gt;Add to Index 图20 选择整个工程的文件右击-&gt;选择commit… 图21 图22 图23 图24 图25 同样在另一个工程文件夹下拉取后能看到克隆的文件。 图26 里面的内容也同步更新了。]]></content>
      <categories>
        <category>git&amp;GitHub</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Git与Github使用笔记》第4章 Tortoise Git]]></title>
    <url>%2F2018%2F12%2F05%2FGit%2F%E7%AC%AC4%E7%AB%A0%20Tortoise%20Git%2F</url>
    <content type="text"><![CDATA[4.1 Tortoise Git的安装及汉化TortoiseGit的安装很简单，笔者就不在一步一步讲解了。汉化就是安装了个汉化包。 图1 【注意】汉化包的位数必须和TortoiseGit相一致。下载地址：https://tortoisegit.org/download/在空白处单击右键有如下图显示表示安装成功。 图2 接下来就对其进行设置成中文，在空白处单击鼠标右键-&gt;TortoiseGit-&gt;Setting。 图3 按照下图中步骤即可。 图4 4.2 TortoiseGit的使用 创建仓库在下新建shared.git文件夹，然后在新建的库文件D:\Git\Git\Repository\Git\shared.git目录下单击右键-&gt;Git在这里创建版本库(Y)… 图5 提示如下图。 图6  克隆文件并提交 再在工作目录D:\Git\work下新建两个文件夹。 ![这里写图片描述](第4章 Tortoise Git/图7.png) 图7 进入Bruceou目录下，鼠标右击-&gt;Git克隆… 图8 克隆库文件。 图9 图10 在在工作目录D:\Git\work\Bruceou文件目录下新建index.txt，并输入Bruceou add the file. 图11 图12 图13 图14 如下显示表提交成功。 图15 然后再同步到库。 图16 图17  克隆库文件及同步在另一个用户目录下克隆文件看库。 图18 图19克隆库文件 图20 拉取后在此工作目录也能看到index.txt。 ![这里写图片描述](第4章 Tortoise Git/图21.png) 图21]]></content>
      <categories>
        <category>git&amp;GitHub</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Git与Github使用笔记》第3章 Git相关配置]]></title>
    <url>%2F2018%2F12%2F05%2FGit%2F%E7%AC%AC3%E7%AB%A0%20Git%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[图1工作区、版本库、暂存区的关系图  查看文件记录命令：git log – pretty=raw进入Ouxiaolong的Git Bash： 图2  查看对象命令：git cat-file -t 哈希值（一般写前6位即可） 图3  查看对象的内容命令：git cat-file -p 哈希值（一般写前6位即可） 图4 一级一级追溯，最终追溯到文件的内容。 图5 进入用户Bruceou的Git Bash： 图6 图7  比较不同命令：git diffgit diff –staged //比较workspace VS stagedgit diff –cached //staged VS local repo  查看分支及创建分支命令：git branch命令：git branch 分支名 //创建分支命令：git checkout 分支名 //切换分支命令]]></content>
      <categories>
        <category>git&amp;GitHub</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Git与Github使用笔记》第2章 Git命令的基本操作]]></title>
    <url>%2F2018%2F12%2F05%2FGit%2F%E7%AC%AC2%E7%AB%A0%20Git%E5%91%BD%E4%BB%A4%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[第一步：仓库初始化在Repository/Git目录下点击右键-&gt;Git Bash Here 图1 进入Git Bash命令：git init —bare shared.git 图2 如图表明初始化成功。 ===================================开发人员1操作================================ 第二步：复制仓库到本地命令：git clone /D/Git/Git/Repository/Git/shared.git . (注意有个点，表明当前目录) 图3 第三步：设置个人信息git config： —system：操作/etc/gitconfig文件：包含了适用于系统所有用户和所有库的值。 —global：操作~/.git config文件：具体到你的用户 缺省：操作仓库.git/config文件命令：git config user.name “user1”//用户名git config user.email user1@163.com//用户邮箱 图4 用ls –al命令可以看到隐藏文件。如下图所示。 图5 进入.git文件夹，查看配置文件。命令：cat congfig 图6 第四步：忽略无需版本控制的文档命令：echo “*.txt” &gt; .gitignore 第五步：新建一个文件命令：echo “User1 add content” &gt; index.txt 图7 查看是否添加成功。 图8 第六步：提交文件命令：git add index.txt 图9 命令：git commit 图10 命令：首行添加：Bruceou add the file保存退出，如下图表示成功。 图11 第七步：把自己的仓库提交到公共服务器命令：git push origin master 图12 =================================开发人员2操作================================== 第八步：复制仓库到本地命令：git clone /D/Git/Git/Repository/Git/shared.git .//本地克隆命令：git clone git@github.com:Ouxiaolong/Smart_Home.git //远程克隆 图13 第九步：设置个人信息命令：git config user.name “user2”git config user.email user2@163.com 图14 第十步：忽略无需版本控制的文档命令：echo “*.txt” &gt; .gitignore 第十一步：新建一个文件命令：echo “User2 add content” &gt;&gt; index.txt 图15 第十二步：提交文件命令：git add index.txt 图16 命令：git commit -m “Ouxiaolong add the file!” 图17 第十三步：把自己的仓库提交到公共服务器命令：git push origin master 图18 查看状态：命令：git status =================================开发人员1操作================================== 第十四步：下载服务器最新数据git pull]]></content>
      <categories>
        <category>git&amp;GitHub</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Git与Github使用笔记》第1章 Git入门]]></title>
    <url>%2F2018%2F12%2F05%2FGit%2F%E7%AC%AC1%E7%AB%A0%20Git%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[1.1 Git介绍1.1.1 Git 简介Linus的第二个伟大作品。2005年由于BitKeeper软件公司对Linux社区停止了免费使用权。Linus迫不得已自己开发了一个分布式的的版本控制工具，从而Git就诞生了。目前使用Git作为版本控制的开源软件：Linux kernel、Android、jQuery、Ruby on Rails…Eclipse 上使用Git的项目数量已经超过了使用SVN的仓库数。 1.1.2 Git的优势 分布式、离线操作 每日工作备份 异地协同工作 现场版本控制 避免引入辅助目录 工作进度随时保存 快 1.1.3 Git的工作模型 集中式协同的模型 图1  社交网络式分布模型 图2 1.1.4 Git基本交互流程图 图3 好了，下面进行安装。 1.2 Git安装过程下载地址：https://git-scm.com/downloads/1.双击安装程序“Git-2.12.0-64-bit”，如图所示。目前（2017-11-07）最新的版本是2.15.0，读者朋友要想使用最新的版本请自行下载。 图4 2.点击“Next”，根据自己的情况，选择程序的安装目录。如图所示。 图5 3.继续点击“Next”，显示截图如下： 图6 说明：（1）图标组件(Addition icons) : 选择是否创建桌面快捷方式。（2）桌面浏览(Windows Explorer integration) : 浏览源码的方法，使用bash 或者 使用Git GUI工具。（3）关联配置文件 : 是否关联 git 配置文件, 该配置文件主要显示文本编辑器的样式。（4）关联shell脚本文件 : 是否关联Bash命令行执行的脚本文件。（5）使用TrueType编码 : 在命令行中是否使用TruthType编码, 该编码是微软和苹果公司制定的通用编码。4.选择完之后，点击“Next”，显示截图如下： &lt; 图7 开始菜单快捷方式目录：设置开始菜单中快捷方式的目录名称, 也可以选择不在开始菜单中创建快捷方式。5.点击“Next”，显示截图如下： 图8 设置环境变量选择使用什么样的命令行工具，一般情况下我们默认使用Git Bash即可：（1）Git自带：使用Git自带的Git Bash命令行工具。（2）系统自带CMD：使用Windows系统的命令行工具。（3）二者都有：上面二者同时配置，但是注意，这样会将windows中的find.exe 和 sort.exe工具覆盖，如果不懂这些尽量不要选择。6.选择之后，继续点击“Next”，显示如下： 图9 7.选择之后，点击“Next”，显示截图如下： 图10 8.选择之后，点击“Next”，显示截图如下： 图11 选择提交的时候换行格式（1）检查出windows格式转换为unix格式：将windows格式的换行转为unix格式的换行再进行提交。（2）检查出原来格式转为unix格式：不管什么格式的，一律转为unix格式的换行再进行提交。（3）不进行格式转换 : 不进行转换，检查出什么，就提交什么。9.选择之后，点击“Next”，显示截图如下： 图12 10.选择之后，点击“Install”，开始安装，截图显示如下： 图13 11.安装完成之后，显示截图如下： 图14 这样，我们的Git客户端就下载并安装完成了。Git英文手册在安装目录下：C:\Program Files\Git【注】具体英文手册的路径根据安装路径决定，请读者根据自己的实际安装路径查找手册。 1.3 Git Bash配置1.从开始菜单中找到Git Bash，点击打开之后，显示如下： 图15 2.点击左上角的图标，在下拉菜单中选择“Options…”，点击之后会弹出Git Bash的配置界面，可以根据自己的需要进行配置，操作过程截图如下： 图16]]></content>
      <categories>
        <category>git&amp;GitHub</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Git与Github使用笔记》第10章 GitHub删除repository]]></title>
    <url>%2F2018%2F12%2F05%2FGit%2F%E7%AC%AC10%E7%AB%A0%20GitHub%E5%88%A0%E9%99%A4repository%2F</url>
    <content type="text"><![CDATA[在GitHub上创建一些项目后，有些可能不满意想要删除，接下来笔者就教大家如何删除项目。首先进入github登录上自己的帐号，我们这里以Test为例，选择Test。 图1 进入Test项目页面，找到settings，点击settings。 图2 向下拉找到Delete this repositoty，点击它。 图3 弹出如下对话框，需要输入项目名称，这里是Test。 图4 点击下方按钮，删除成功转入到成功提示页面，再看主页已经没有了Test。当然删除谨慎额！删除前三思啊！朋友们！]]></content>
      <categories>
        <category>git&amp;GitHub</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
</search>
